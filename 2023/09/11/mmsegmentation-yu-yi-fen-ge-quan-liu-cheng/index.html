<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="MMSegmentation语义分割全流程, cout&gt;&gt;.&lt;&lt;cin"><meta name="baidu-site-verification" content="fmlEuI34ir"><meta name="google-site-verification" content="yCy2azpds5XSuGZvis6OuA-XIGF5GuGpYRAaGfD6o48"><meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7"><meta name="description" content="MMSegmentation语义分割全流程环境安装在这一部分，我首先安装配置了MMSegmentation，利用colab平台进行搭建，基本的信息如下：

这里使用的GPU为colab给出的基础款，即Tesla T4。
在之后的过程中，我在"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>MMSegmentation语义分割全流程 | cout&gt;&gt;.&lt;&lt;cin</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><style type="text/css"></style><script src="/libs/jquery/jquery-2.2.0.min.js"></script><script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ce84511d3df71640a9378a69f6293044";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script>document.write('<script src="https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba" id="sozz"><\/script>')</script><meta name="generator" content="Hexo 5.4.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">cout>>.<<cin</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a><ul class="right"><li class="hide-on-med-and-down"><a href="/" class="waves-effect waves-light"><i class="fa fa-home"></i> <span>首页</span></a></li><li class="hide-on-med-and-down"><a href="/tags" class="waves-effect waves-light"><i class="fa fa-tags"></i> <span>标签</span></a></li><li class="hide-on-med-and-down"><a href="/categories" class="waves-effect waves-light"><i class="fa fa-bookmark"></i> <span>分类</span></a></li><li class="hide-on-med-and-down"><a href="/archives" class="waves-effect waves-light"><i class="fa fa-archive"></i> <span>归档</span></a></li><li class="hide-on-med-and-down"><a href="/about" class="waves-effect waves-light"><i class="fa fa-user-circle-o"></i> <span>关于</span></a></li><li class="hide-on-med-and-down"><a href="/friends" class="waves-effect waves-light"><i class="fa fa-address-book"></i> <span>友情链接</span></a></li><li class="hide-on-med-and-down"><a href="/contact" class="waves-effect waves-light"><i class="fa fa-comments"></i> <span>Contact</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fa fa-search" title="搜索"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">cout>>.<<cin</div><div class="logo-desc">大连理工大学|软件工程|创中</div></div><ul class="menu-list mobile-menu-list"><li><a href="/" class="waves-effect waves-light"><i class="fa fa-fw fa-home"></i> 首页</a></li><li><a href="/tags" class="waves-effect waves-light"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li><a href="/categories" class="waves-effect waves-light"><i class="fa fa-fw fa-bookmark"></i> 分类</a></li><li><a href="/archives" class="waves-effect waves-light"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li><a href="/about" class="waves-effect waves-light"><i class="fa fa-fw fa-user-circle-o"></i> 关于</a></li><li><a href="/friends" class="waves-effect waves-light"><i class="fa fa-fw fa-address-book"></i> 友情链接</a></li><li><a href="/contact" class="waves-effect waves-light"><i class="fa fa-fw fa-comments"></i> Contact</a></li><li><div class="divider"></div></li><li><a href="https://github.com/xhsioi/xhsioi.github.io" class="waves-effect waves-light" target="_blank"><i class="fa fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/xhsioi/xhsioi.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/15.jpg)"><div class="container"><div class="row"><div class="col s12 m12 l12"><div class="brand"><div class="description center-align post-title">MMSegmentation语义分割全流程</div></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px}#toc-content .is-active-link{color:#42b983}#toc-content .is-active-link::before{background-color:#42b983}#floating-toc-btn{position:fixed;right:20px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/" target="_blank"><span class="chip bg-color">语义分割</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/Datawhale/" class="post-category" target="_blank">Datawhale</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-09-11</div><div class="post-author info-break-policy"><i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp; xhsioi</div><div class="info-break-policy"><i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp; 3k</div><div class="info-break-policy"><i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp; 10 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="MMSegmentation语义分割全流程"><a href="#MMSegmentation语义分割全流程" class="headerlink" title="MMSegmentation语义分割全流程"></a>MMSegmentation语义分割全流程</h1><h3 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h3><p>在这一部分，我首先安装配置了MMSegmentation，利用colab平台进行搭建，基本的信息如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309102210670.png"></p><p>这里使用的GPU为colab给出的基础款，即Tesla T4。</p><p>在之后的过程中，我在设置Matplotlib中文字体时出现了问题，即无法正常显示中文的情况：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309102213884.png"></p><p>搜索得知，colab的虚拟机ubuntu的操作系统没有支持中文的字体，matplotlib配置文件没有支持中文的字体。在matplotlib文件夹中添加tff文件后重新导入依旧存在这个问题，因此直接在代码中引用：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import matplotlib.pyplot as plt
import matplotlib as mpl
zhfont = mpl.font_manager.FontProperties(fname='/usr/share/fonts/truetype/liberation/simhei.ttf')
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>然后在绘制的过程中引用即可：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt.plot([1,2,3], [100,500,300])
plt.title('matplotlib中文字体测试', fontsize=25,  fontproperties=zhfont)
plt.xlabel('X轴', fontsize=15,  fontproperties=zhfont)
plt.ylabel('Y轴', fontsize=15, fontproperties=zhfont)
plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309102217264.png"></p><h3 id="OpenMMLab简述"><a href="#OpenMMLab简述" class="headerlink" title="OpenMMLab简述"></a>OpenMMLab简述</h3><p>OpenMMLab作为一个有广泛影响力的人工智能计算机视觉开原算法体系，涉及到图像识别分类、目标检测等多个领域，可以用于开发各种项目，是各类论文的集大成之作。常见算法库有目标检测算法库（MMDetection、MMYOLO）、文字检测识别算法库（MMOCR）、3D目标检测算法库、旋转目标检测算法库（MMRote）、图像分割算法库（MMSegmentation）、图像分类+预训练+多模态算法库（MMPretrain）、高精度姿态估计算法RTMPose等等。之前对视觉问答相关论文进行复现时，出现了baseline准确度较低的情况，我想可以基于MMPretrain对源代码进行修改，提升反事实样本数据的生成效果。</p><p>MMYOLO：轻松获得不同版本YOLO在同一个数据集上的跑分；</p><p>MMOCR：文本检测、文本识别和关键信息提取；</p><h3 id="单张图像预训练处理（Segformer算法）"><a href="#单张图像预训练处理（Segformer算法）" class="headerlink" title="单张图像预训练处理（Segformer算法）"></a>单张图像预训练处理（Segformer算法）</h3><p>首先发现之前的环境没有搭载在google drive上，因此今天重新配了一遍。首先是利用Segformer算法实现在Cityscpaes数据集上的预训练，效果如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309121928862.png"></p><p>这里由于是第一次接触Segformer算法，因此进行了较为深入的了解。SegFormer由两部分组成，即一个拥有多头注意力的Transformer encoder，以及一个由多层感知机构成的decoder。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309121943297.webp"></p><p>从图中可以看到，encoder是由连续的多个transformer构成，每个transformer模块中都部署了多头注意力模块、归一层和混合前馈神经网络层。</p><ul><li>分层特征表示：生成一系列不同分辨率大小的特征，即将N x N x 3的patch，转化为1 x 1 x c的向量，使用Patch merging的方法。</li><li>多头注意力机制：添加了缩放因子R，降低每个注意力模块的计算复杂度。</li><li>混合前缀神经网络：语义分割任务对于位置编码是不必要的，仅仅通过3x3的卷积就足以动态表达patch间的位置关系。</li></ul><p>然后是轻量的decoder，之所以能够构建如此简单的解码器，就是在之前的分层transformer结构接收域更加广泛。论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2105.15203">https://arxiv.org/abs/2105.15203</a> 后续再对文章进行精读和复现，感觉其中的缩放因子的加入过于唐突，应该进一步了解一下。</p><h3 id="预训练语义分割模型预测"><a href="#预训练语义分割模型预测" class="headerlink" title="预训练语义分割模型预测"></a>预训练语义分割模型预测</h3><p>由于这一部分使用的算法和上述单张图像相同，因此不再赘述。需要注意的是API效果更好，训练更快。下面是我对我拍摄的一组视频进行训练。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309141948137.png"></p><p>显示的结果不是很好，如下图所示。这里推测是因为出现物体较多，以及光源的问题。在我拍摄的视频中光线的分布并不均匀，相较于教程给出的视频噪音过多，恰好从侧面指出了预训练模型的问题，待与之后的模型进行对比后再进行深入研究。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309151914649.png"></p><h3 id="构建分割数据集"><a href="#构建分割数据集" class="headerlink" title="构建分割数据集"></a>构建分割数据集</h3><p>这里不再赘述，整体数据分为训练集和验证集，分文件存储图片和标注。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309151927310.png"></p><h3 id="可视化数据结果"><a href="#可视化数据结果" class="headerlink" title="可视化数据结果"></a>可视化数据结果</h3><p>这里主要讲如何绘图和着色，以及批量可视化结果，不再赘述。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309151935290.png"></p><h3 id="语义分割算法介绍"><a href="#语义分割算法介绍" class="headerlink" title="语义分割算法介绍"></a>语义分割算法介绍</h3><p>这一部分对七种网络的配置文件进行了介绍，主要讲的是相关配置文件的安装，这里深入地学习一下各种算法实现的机理。</p><h4 id="UNet"><a href="#UNet" class="headerlink" title="UNet"></a>UNet</h4><p>论文链接：<a target="_blank" rel="noopener" href="https://paperswithcode.com/method/u-net">https://paperswithcode.com/method/u-net</a></p><p>提出背景：对于医学图像的处理中，需要对每一个像素进行标注，但是无法获得数钱个训练图像，因此基于FCN进行了数据增强操作，提出了一种U型的网络结构可以同时获取上下文的信息。</p><p>组成：下采样（特征提取）、上采样和跳跃连接。其中红色箭头代表最大池化操作，蓝色箭头代表卷积操作。在上采样中保存了大量的通道，保证更高的分辨率。此外还使用了 Overlap-tile策略补全输入图像上下信息。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309152041636.webp"></p><h4 id="DeepLabV3"><a href="#DeepLabV3" class="headerlink" title="DeepLabV3+"></a>DeepLabV3+</h4><p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.02611.pdf">https://arxiv.org/pdf/1802.02611.pdf</a></p><p>结构：十分明显的Decoder和Encoder结构</p><h6 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h6><p>包括backbone以及ASPP（空洞卷积层）</p><p>其中backbone有两种网络结构：将layer4改为空洞卷积的Resnet系列、改进的Xception。从backbone出来的feature map分两部分：一部分是最后一层卷积输出的feature maps，另一部分是中间的低级特征的feature maps；backbone输出的第一部分送入ASPP模块，第二部分则送入Decoder模块。<br>ASPP模块接受backbone的第一部分输出作为输入，使用了四种不同膨胀率的空洞卷积块（包括卷积、BN、激活层）和一个全局平均池化块（包括池化、卷积、BN、激活层）得到一共五组feature maps，将其concat起来之后，经过一个1*1卷积块（包括卷积、BN、激活、dropout层），最后送入Decoder模块。</p><h6 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h6><p>在Decoder部分，接收来自backbone中间层的低级feature maps和来自ASPP模块的输出作为输入。</p><p>首先，对低级feature maps使用1*1卷积进行通道降维，从256降到48（之所以需要降采样到48，是因为太多的通道会掩盖ASPP输出的feature maps的重要性，且实验验证48最佳）；<br>然后，对来自ASPP的feature maps进行插值上采样，得到与低级featuremaps尺寸相同的feature maps；<br>接着，将通道降维的低级feature maps和线性插值上采样得到的feature maps使用concat拼接起来，并送入一组3*3卷积块进行处理；<br>最后，再次进行线性插值上采样，得到与原图分辨率大小一样的预测图。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309152050358.png"></p><h4 id="PSPNet"><a href="#PSPNet" class="headerlink" title="PSPNet"></a>PSPNet</h4><p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1612.01105">https://arxiv.org/abs/1612.01105</a></p><ol><li><p>提出金字塔池化模块</p></li><li><p>结合多尺寸信息：SPP(AVE效果优于MAX)</p></li><li><p>上采样：双线性插值</p></li><li><p>Tricks：修改Resnet-101 为 ResNet-103、辅助 loss</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309152113470.png"></p></li></ol><h3 id="训练语义分割模型"><a href="#训练语义分割模型" class="headerlink" title="训练语义分割模型"></a>训练语义分割模型</h3><p>由于这里使用的显卡太拉，即T4，性能上比较差，因此减少训练的次数为5000，训练过程如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309152116500.png"></p><h3 id="可视化训练结果"><a href="#可视化训练结果" class="headerlink" title="可视化训练结果"></a>可视化训练结果</h3><p>首先是对训练损失函数的各项数值统计。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309161932469.png"></p><p>可以看到，在第1000次训练结束之后就已经产生了收敛的趋势，在4000-5000次训练部分趋于稳定状态。对比教程中的图像发现基本符合。然后是对测试集评估指标的统计，明显看出其中的趋势，说明模型的训练结果较好。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309161939763.png"></p><p>接着对训练过程各类别评估指标进行研究，这里主要涉及六方面元素，即[‘background’, ‘red’, ‘green’, ‘white’, ‘seed-black’, ‘seed-white’]，这里单独给出green的图像绘制。可以看到F得分维持在稳定的水平，其他各项指标的变化趋势大致相同。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309161941668.png"></p><p>综上所述，模型的训练结果较好，接下来进行给定模型的测试集评估。（P.S.谷歌云盘上传的速度太慢了，这里直接ondrive转google）</p><h3 id="测试集性能评估"><a href="#测试集性能评估" class="headerlink" title="测试集性能评估"></a>测试集性能评估</h3><p>在本次训练过程中以PSPNet为基础，因为训练的迭代次数较少，因此在性能评估的结果上和标准模型差距较大。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309171957303.png"></p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309171956240.png" alt="标准模型"></p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309171956666.png" alt="我的训练结果"></p><p>可以看到，在IoU指标上，整体的表现不好，说明在进行测试集关键对象标注时不能近似完全的标注。对于ACC而言，准确率较高，还有一定的提升空间。Dice参数，用于计算两个样本之间的相似度，这里表示成不同类别内部的相似程度，这里和标准模型的差距不是很大，说明模型整体的算法是适合的，但是对于green类别而言需要更多的迭代实现分辨方法的一般性。</p><h3 id="训练得到的模型进行预测"><a href="#训练得到的模型进行预测" class="headerlink" title="训练得到的模型进行预测"></a>训练得到的模型进行预测</h3><p>这里使用配置文件是基于KNet的实现，对以下图片进行语义分割，对比图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309172019710.png"></p><p>可以看到，西瓜的基本边界以及内部的颜色、西瓜子都实现了较好的分割，这里我们结合图例进行具体的分析。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309172020126.png"></p><p>对比原图，我们可以发现当前模型仍旧存在部分问题，如将黑色的西瓜子识别成白色、部分被勺子遮挡的西瓜子没有被识别出来，这些问题都是在以后对模型进行提升时需要注意的。这里还可以实现将特殊部分提取出来，如白色的西瓜子：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309172024002.png"></p><p>生成多个图像进行评估是不现实的，因此这里着重对生成的混淆矩阵进行分析：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309172026261.png"></p><p>可以看到，识别最为准确的为背景和基本的红色、绿色、白色，而形状最小的西瓜子不容易被识别出来，准确率较低。这也是KNet的简便性的代价。这里可以使用给出的DeepLabv3+模型进行评估，其模型应用的空洞卷积能够更有效地实现小目标检测。</p><h3 id="用训练的模型预测视频"><a href="#用训练的模型预测视频" class="headerlink" title="用训练的模型预测视频"></a>用训练的模型预测视频</h3><p>这里不再赘述，就是逐帧进行处理，不是实时的因此比较简单，这里给出对测试集进行多张预测得到的结果：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309172032866.png"></p><h3 id="语义分割部署"><a href="#语义分割部署" class="headerlink" title="语义分割部署"></a>语义分割部署</h3><p>这一部分在本地进行相关环境的安装，同时进行摄像头的实时预测。其中使用了MMDeploy这一在线模型转换工具，他提供了一系列工具，帮助我们将OpenMMlab上的算法部署到各种设备和平台上，其基本流程如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202309191941025.png"></p><p>模型转换的主要功能是吧输入的模型格式进行转换，转换成目标设备的推理引擎所要求的模型格式。在本次实验过程中，我们将模型部署到PC端和手机端，即将Pytorch模型转换为ONNX模型、TorchScript等和设备无关的IR 模型。</p><h3 id="本地ONNXRuntime部署"><a href="#本地ONNXRuntime部署" class="headerlink" title="本地ONNXRuntime部署"></a>本地ONNXRuntime部署</h3><p>ONNXRuntime是微软推出的一款推理框架，用户可以通过运行其实现基本预测，支持CPU和GPU多种形式，下面对其基本的实现方式进行介绍：</p><ul><li>Session构造：首先创造一个InferenceSession对象，在构造过程中进行各成员的初始化，包括负责OpKernel管理、Session配置信息、图分割、log管理。</li><li>模型加载初始化：将ONNX模型加载到InferenceSession中进行模型加载、Providers注册以及一系列的内存分配、model partition以及kernel注册。</li><li>模型运行：每次读入一个batch的数据并进行计算得到模型的最终输出，顺序调用各个node的对应OpKernel进行计算。</li></ul><h3 id="本地MMDeploy-Runtime部署"><a href="#本地MMDeploy-Runtime部署" class="headerlink" title="本地MMDeploy_Runtime部署"></a>本地MMDeploy_Runtime部署</h3><p>因为前文进行过介绍，这里不再赘述。</p></div><hr><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.88rem}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22ab38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019fe8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fa fa-close"></i></a><h4 class="reward-title">欢迎投喂~</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div></div><script src="/libs/share/js/social-share.min.js"></script><div class="reprint" id="reprint-statement"><p class="reprint-tip"><i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp; <span>转载规则</span></p><div class="center-align"><a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh"><img alt="" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a></div><br><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">《MMSegmentation语义分割全流程》 </span>由 <a xmlns:cc="http://creativecommons.org/ns#" href="/2023/09/11/mmsegmentation-yu-yi-fen-ge-quan-liu-cheng/" property="cc:attributionName" rel="cc:attributionURL">xhsioi </a>采用 <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">知识共享署名 4.0 国际许可协议 </a>进行许可。</div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fa fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2023/10/01/2023-nian-ji-suan-ji-bao-yan-jing-yan-fen-xiang-ci-jiu-rk8/"><div class="card-image"><img src="/medias/featureimages/3.jpg" class="responsive-img" alt="2023年计算机保研经验分享|次九rk8%"> <span class="card-title">2023年计算机保研经验分享|次九rk8%</span></div></a><div class="card-content article-content"><div class="summary block-with-text">2023年计算机保研经验分享|次九rk8%注：本次记录只代表个人观点，仅供参考。 前言首先不得不感慨一下今年计算机保研的艰难程度，今年相比往年更加注重综合能力的考核，已然不是绩点为王的时代了。非常难受的是，我的绩点、科研和竞赛都比较平平无奇</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2023-10-01 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E4%BF%9D%E7%A0%94/" class="post-category" target="_blank">保研</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/" target="_blank"><span class="chip bg-color">经验分享</span> </a><a href="/tags/%E6%9D%82%E8%AE%B0/" target="_blank"><span class="chip bg-color">杂记</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fa fa-chevron-right"></i></div><div class="card"><a href="/2023/08/22/cvpr2020-counterfactual-samples-synthesizing-for-robust-vqa-note/"><div class="card-image"><img src="/medias/featureimages/14.jpg" class="responsive-img" alt="CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note"> <span class="card-title">CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note</span></div></a><div class="card-content article-content"><div class="summary block-with-text">CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note[TOC] 相关背景Question Only Model（RUBi）https://blog.csdn.net</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2023-08-22 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category" target="_blank">论文</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" target="_blank"><span class="chip bg-color">论文研读</span> </a><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94/" target="_blank"><span class="chip bg-color">视觉问答</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: cout>>.<<cin<br />作者: xhsioi<br />链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fa fa-list"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><footer class="page-footer bg-color"><div class="container row center-align"><div class="col s12 m8 l8 copy-right">&nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp; <span class="white-color">93.3k</span><br><span id="sitetime"></span><br><span id="busuanzi_container_site_pv" style="display:none"><i class="fa fa-heart-o"></i> 本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span> </span><span id="busuanzi_container_site_uv" style="display:none">人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.</span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fa fa-github"></i> </a><a href="mailto:m18846242315@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa fa-envelope-open"></i> </a><a href="https://zhihu.com/people/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-inverse">知</i> </a><a href="http://wpa.qq.com/msgrd?v=3&uin=2848220300&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2021,10,5,12,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><link rel="stylesheet" href="/css/prism.css"><script src="/js/prism.js" async></script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fa fa-angle-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script type="text/javascript">var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="Σ(っ °Д °;)っ你给我回来李和鑫！",clearTimeout(st)):(document.title="φ(゜▽゜*)♪你回来辣！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/miku.model.json"},display:{superSample:2,position:"left",width:150,height:300,hOffset:30,vOffset:-30},mobile:{show:!0,scale:.6},react:{opacity:.7},name:{canvas:"live2dcanvas",div:"live2d-widget"},dev:{border:!1},dialog:{enable:!0,hitokoto:!0}})</script></body></html>