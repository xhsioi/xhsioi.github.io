<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="python数据分析大作业（三）——机器学习的微型WAF, cout&gt;&gt;.&lt;&lt;cin"><meta name="baidu-site-verification" content="fmlEuI34ir"><meta name="google-site-verification" content="yCy2azpds5XSuGZvis6OuA-XIGF5GuGpYRAaGfD6o48"><meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7"><meta name="description" content="恶意URL检测：基于TF-IDF特征向量进行机器学习的微型WAF数据源： Github开源数据集https://github.com/faizann24/Using-machine-learning-to-detect-malicious-"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>python数据分析大作业（三）——机器学习的微型WAF | cout&gt;&gt;.&lt;&lt;cin</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><style type="text/css"></style><script src="/libs/jquery/jquery-2.2.0.min.js"></script><script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ce84511d3df71640a9378a69f6293044";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script>document.write('<script src="https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba" id="sozz"><\/script>')</script><meta name="generator" content="Hexo 5.4.0"><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">cout>>.<<cin</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a><ul class="right"><li class="hide-on-med-and-down"><a href="/" class="waves-effect waves-light"><i class="fa fa-home"></i> <span>首页</span></a></li><li class="hide-on-med-and-down"><a href="/tags" class="waves-effect waves-light"><i class="fa fa-tags"></i> <span>标签</span></a></li><li class="hide-on-med-and-down"><a href="/categories" class="waves-effect waves-light"><i class="fa fa-bookmark"></i> <span>分类</span></a></li><li class="hide-on-med-and-down"><a href="/archives" class="waves-effect waves-light"><i class="fa fa-archive"></i> <span>归档</span></a></li><li class="hide-on-med-and-down"><a href="/about" class="waves-effect waves-light"><i class="fa fa-user-circle-o"></i> <span>关于</span></a></li><li class="hide-on-med-and-down"><a href="/friends" class="waves-effect waves-light"><i class="fa fa-address-book"></i> <span>友情链接</span></a></li><li class="hide-on-med-and-down"><a href="/contact" class="waves-effect waves-light"><i class="fa fa-comments"></i> <span>Contact</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fa fa-search" title="搜索"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">cout>>.<<cin</div><div class="logo-desc">大连理工大学|软件工程|创中</div></div><ul class="menu-list mobile-menu-list"><li><a href="/" class="waves-effect waves-light"><i class="fa fa-fw fa-home"></i> 首页</a></li><li><a href="/tags" class="waves-effect waves-light"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li><a href="/categories" class="waves-effect waves-light"><i class="fa fa-fw fa-bookmark"></i> 分类</a></li><li><a href="/archives" class="waves-effect waves-light"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li><a href="/about" class="waves-effect waves-light"><i class="fa fa-fw fa-user-circle-o"></i> 关于</a></li><li><a href="/friends" class="waves-effect waves-light"><i class="fa fa-fw fa-address-book"></i> 友情链接</a></li><li><a href="/contact" class="waves-effect waves-light"><i class="fa fa-fw fa-comments"></i> Contact</a></li><li><div class="divider"></div></li><li><a href="https://github.com/xhsioi/xhsioi.github.io" class="waves-effect waves-light" target="_blank"><i class="fa fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/xhsioi/xhsioi.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/28.jpg)"><div class="container"><div class="row"><div class="col s12 m12 l12"><div class="brand"><div class="description center-align post-title">python数据分析大作业（三）——机器学习的微型WAF</div></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px}#toc-content .is-active-link{color:#42b983}#toc-content .is-active-link::before{background-color:#42b983}#floating-toc-btn{position:fixed;right:20px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/python/" target="_blank"><span class="chip bg-color">python</span> </a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BC%8C%E7%88%AC%E8%99%AB/" target="_blank"><span class="chip bg-color">数据分析，爬虫</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" class="post-category" target="_blank">大作业</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-08-30</div><div class="post-author info-break-policy"><i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp; xhsioi</div><div class="info-break-policy"><i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp; 5.2k</div><div class="info-break-policy"><i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp; 23 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="恶意URL检测：基于TF-IDF特征向量进行机器学习的微型WAF"><a href="#恶意URL检测：基于TF-IDF特征向量进行机器学习的微型WAF" class="headerlink" title="恶意URL检测：基于TF-IDF特征向量进行机器学习的微型WAF"></a><strong>恶意URL检测：基于TF-IDF特征向量进行机器学习的微型WAF</strong></h1><p><strong>数据源：</strong> Github开源数据集<a target="_blank" rel="noopener" href="https://github.com/faizann24/Using-machine-learning-to-detect-malicious-URLs">https://github.com/faizann24/Using-machine-learning-to-detect-malicious-URLs</a></p><p><a target="_blank" rel="noopener" href="https://github.com/exp-db/AI-Driven-WAF">https://github.com/exp-db/AI-Driven-WAF</a></p><p><a target="_blank" rel="noopener" href="https://github.com/Echo-Ws/UrlDetect">https://github.com/Echo-Ws/UrlDetect</a></p><p><strong>摘要</strong></p><p>随着互联网科技的不断发展，工信部近期指出，过去十年我国已建成全球规模最大的网络基础设施。不断完善的网络基础设施能够给我们带来很多便捷的应用，同时也带来了很多新式网络安全风险。由于传统的黑名单式的过滤规则依赖人工修改，随着网络环境的发展增删管理成本将迅速增高。因此本文尝试通过一些常见的机器学习方法来构建一个不依赖硬编码规则的微型防火墙，对恶意的URL进行检测并拦截。使用的模型主要有逻辑斯蒂回归、SVM支持向量机、朴素贝叶斯等。同时由于目标数据的文本形式，还需要首先筛选每个URL中的关键词，生成TF-IDF特征向量。最后本文对由不同方法产生的模型进行了测试和结果分析，测试结果中发现，利用逻辑斯蒂回归方案构建的恶意URL检测系统,在测试集上表现出了较好的分类性能，在正确率、召回率、精确率、F1值上表现出了较好的综合性能，同时不会产生过拟合现象。最后本文使用flask框架装载此模型，构建了一个restfulAPI，演示了该微型防火墙的可能工作模式。</p><p><strong>关键词：</strong>URL；恶意检测；SVM支持向量机；逻辑回归；朴素贝叶斯；TF-IDF；</p><h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a><strong>研究背景</strong></h2><p>OWASP统计的2021全球Web安全问题Top 10中，权限控制失效和注入式攻击分别占到第一位和第三位。权限控制包含用户cookie、jwt、序列化数据的篡改，以及CORS跨域的错误配置导致未经授权的API恶意访问；注入式攻击包含sql、ldap、ognl、xml注入等。而这些漏洞的利用基本上都依靠URL或者报文的其他部分当作载体，并且明显有相当一部分共通的特征，故而有可能使用机器学习进行一定的预防。著名网络安全解决方案服务商卡巴斯基指出：在机器学习的支持下，AI 网络安全将在不久的将来成为一种强大的工具。与其他行业一样，人工交互在安全方面长期以来是必不可少且不可替代的。尽管目前网络安全严重依赖于人工操作，但我们逐渐看到，在处理特定任务时，科技已经比人类效率更高。</p><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a><strong>数据准备</strong></h2><h3 id="获取URL请求数据集"><a href="#获取URL请求数据集" class="headerlink" title="获取URL请求数据集"></a><strong>获取URL请求数据集</strong></h3><p>本文的URL请求数据均采集于GitHub的开源数据集，其中包含带有标记的正常请求数据1,265,974条，恶意请求数据44,530条</p><h3 id="URL解码统一格式"><a href="#URL解码统一格式" class="headerlink" title="URL解码统一格式"></a><strong>URL解码统一格式</strong></h3><p>收集的请求数据中既有URL编码一次或多次的请求，也有原始的请求，故需要对URL进行循环解码统一格式。</p><h3 id="数据集去重"><a href="#数据集去重" class="headerlink" title="数据集去重"></a><strong>数据集去重</strong></h3><p>收集的请求数据中存在常见的恶意请求，例如sql注入万能密码：foo.com?foo=0’ or 1=1#以及常见XSS攻击：foo.com?foo=<script>alert("xss")</script>等，很大概率会在各数据集中大批量重合，而且重合程度各不相同。故需要对数据进行去重，防止训练时影响参数的权重而导致模型效果欠佳。</p><h3 id="替换-x2F-去除不合规字符"><a href="#替换-x2F-去除不合规字符" class="headerlink" title="替换/去除不合规字符"></a><strong>替换/去除不合规字符</strong></h3><p>由于种种原因，收集的数据中还存在不合规的字符，比如中文的单双引号、全角数字、非utf-8编码的字符等。本文对可识别、可替换的不合规字符进行了替换操作，而对由于编码等问题导致的无意义字符进行了数据去除操作。</p><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a><strong>模型训练</strong></h2><p>本文的模型训练用到了scikit-learn(sklearn)==0.19.2以及numpy、scipy三个python库</p><h3 id="将URL字符串转换为TF-IDF特征矩阵"><a href="#将URL字符串转换为TF-IDF特征矩阵" class="headerlink" title="将URL字符串转换为TF-IDF特征矩阵"></a><strong>将URL字符串转换为TF-IDF特征矩阵</strong></h3><p>TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</p><p>使用sklearn.feature_extraction.text的TfidfVectorizer函数可以对目标文本生成TF-IDF特征向量，定义矢量化函数为TF-IDF矢量函数实例：self.vectorizer = TfidfVectorizer(tokenizer=self.get_ngrams)。</p><p>其中tokenizer=self.get_ngrams为自定义的生成特征值的方法，本文通过对URL进行分组生成特征，每组由2-5个字符组成，步长为1来取特征向量组成数组，提交给TF-IDF矢量函数。</p><h3 id="应用不同模型进行训练"><a href="#应用不同模型进行训练" class="headerlink" title="应用不同模型进行训练"></a><strong>应用不同模型进行训练</strong></h3><h4 id="应用逻辑斯蒂回归模型进行训练"><a href="#应用逻辑斯蒂回归模型进行训练" class="headerlink" title="应用逻辑斯蒂回归模型进行训练"></a><strong>应用逻辑斯蒂回归模型进行训练</strong></h4><p>使用sklearn.linear_model的LogisticRegression函数能够对数据进行线性拟合，然后使用激励函数逻辑斯蒂函数将其处理到0至1的区间，步步迭代，从而分类正常请求和恶意请求。</p><h4 id="应用svm支持向量机模型进行训练"><a href="#应用svm支持向量机模型进行训练" class="headerlink" title="应用svm支持向量机模型进行训练"></a><strong>应用svm支持向量机模型进行训练</strong></h4><p>使用sklearn.svm的LinearSVC函数能够自动对数据寻找不同集合之间的最大超平面，从而分类正常请求和恶意请求。</p><h4 id="应用朴素贝叶斯模型进行训练"><a href="#应用朴素贝叶斯模型进行训练" class="headerlink" title="应用朴素贝叶斯模型进行训练"></a><strong>应用朴素贝叶斯模型进行训练</strong></h4><p>使用sklearn.naive_bayes的MultinomialNB函数能够计算各特征的概率，对其使用最大似然估计方法，估计参数的值。</p><h2 id="准确度评测"><a href="#准确度评测" class="headerlink" title="准确度评测"></a><strong>准确度评测</strong></h2><p>使用sklearn.metrics的classification_report函数，能够提供包含精确率、召回率、F1值等的完整报告。如下为三种模型的预测结果报告。</p><h3 id="逻辑斯蒂回归预测结果"><a href="#逻辑斯蒂回归预测结果" class="headerlink" title="逻辑斯蒂回归预测结果"></a><strong>逻辑斯蒂回归预测结果</strong></h3><h4 id="定义向量中单个元素包含两个字符"><a href="#定义向量中单个元素包含两个字符" class="headerlink" title="定义向量中单个元素包含两个字符"></a><strong>定义向量中单个元素包含两个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>1.00</td><td>1.00</td><td>1.00</td><td>316542</td></tr><tr><td>恶意请求</td><td>0.99</td><td>0.94</td><td>0.96</td><td>11084</td></tr><tr><td>avg / total</td><td>1.00</td><td>1.00</td><td>1.00</td><td>327626</td></tr></tbody></table><h4 id="定义向量中单个元素包含三个字符"><a href="#定义向量中单个元素包含三个字符" class="headerlink" title="定义向量中单个元素包含三个字符"></a><strong>定义向量中单个元素包含三个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>1.00</td><td>1.00</td><td>1.00</td><td>316542</td></tr><tr><td>恶意请求</td><td>1.00</td><td>0.94</td><td>0.97</td><td>11084</td></tr><tr><td>avg / total</td><td>1.00</td><td>1.00</td><td>1.00</td><td>327626</td></tr></tbody></table><p>模型的准确度:0.9978969923021982</p><h4 id="定义向量中单个元素包含四个字符"><a href="#定义向量中单个元素包含四个字符" class="headerlink" title="定义向量中单个元素包含四个字符"></a><strong>定义向量中单个元素包含四个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>1.00</td><td>1.00</td><td>1.00</td><td>316542</td></tr><tr><td>恶意请求</td><td>1.00</td><td>0.93</td><td>0.96</td><td>11084</td></tr><tr><td>avg / total</td><td>1.00</td><td>1.00</td><td>1.00</td><td>327626</td></tr></tbody></table><p>模型的准确度:0.9975520868307155</p><h3 id="svm支持向量机预测结果"><a href="#svm支持向量机预测结果" class="headerlink" title="svm支持向量机预测结果"></a><strong>svm支持向量机预测结果</strong></h3><h4 id="定义向量中单个元素包含两个字符-1"><a href="#定义向量中单个元素包含两个字符-1" class="headerlink" title="定义向量中单个元素包含两个字符"></a><strong>定义向量中单个元素包含两个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>1.00</td><td>1.00</td><td>1.00</td><td>316542</td></tr><tr><td>恶意请求</td><td>0.99</td><td>0.97</td><td>0.97</td><td>11084</td></tr><tr><td>avg / total</td><td>1.00</td><td>1.00</td><td>1.00</td><td>327626</td></tr></tbody></table><p>模型的准确度:0.998525758028972</p><h4 id="定义向量中单个元素包含三个字符-1"><a href="#定义向量中单个元素包含三个字符-1" class="headerlink" title="定义向量中单个元素包含三个字符"></a><strong>定义向量中单个元素包含三个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>1.00</td><td>1.00</td><td>1.00</td><td>316542</td></tr><tr><td>恶意请求</td><td>1.00</td><td>0.98</td><td>0.99</td><td>11084</td></tr><tr><td>avg / total</td><td>1.00</td><td>1.00</td><td>1.00</td><td>327626</td></tr></tbody></table><p>模型的准确度:0.9993468161867495</p><h4 id="定义向量中单个元素包含四个字符-1"><a href="#定义向量中单个元素包含四个字符-1" class="headerlink" title="定义向量中单个元素包含四个字符"></a><strong>定义向量中单个元素包含四个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>1.00</td><td>1.00</td><td>1.00</td><td>316542</td></tr><tr><td>恶意请求</td><td>1.00</td><td>0.98</td><td>0.99</td><td>11084</td></tr><tr><td>avg / total</td><td>1.00</td><td>1.00</td><td>1.00</td><td>327626</td></tr></tbody></table><h4 id="定义向量中单个元素包含五个字符"><a href="#定义向量中单个元素包含五个字符" class="headerlink" title="定义向量中单个元素包含五个字符"></a><strong>定义向量中单个元素包含五个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>1.00</td><td>1.00</td><td>1.00</td><td>316542</td></tr><tr><td>恶意请求</td><td>1.00</td><td>0.97</td><td>0.98</td><td>11084</td></tr><tr><td>avg / total</td><td>1.00</td><td>1.00</td><td>1.00</td><td>327626</td></tr></tbody></table><h3 id="朴素贝叶斯预测结果"><a href="#朴素贝叶斯预测结果" class="headerlink" title="朴素贝叶斯预测结果"></a><strong>朴素贝叶斯预测结果</strong></h3><h4 id="定义向量中单个元素包含两个字符-2"><a href="#定义向量中单个元素包含两个字符-2" class="headerlink" title="定义向量中单个元素包含两个字符"></a><strong>定义向量中单个元素包含两个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>0.99</td><td>1.00</td><td>1.00</td><td>316542</td></tr><tr><td>恶意请求</td><td>0.90</td><td>0.81</td><td>0.85</td><td>11084</td></tr><tr><td>avg / total</td><td>0.99</td><td>0.99</td><td>0.99</td><td>327626</td></tr></tbody></table><p>模型的准确度:0.9904586327092477</p><h4 id="定义向量中单个元素包含三个字符-2"><a href="#定义向量中单个元素包含三个字符-2" class="headerlink" title="定义向量中单个元素包含三个字符"></a><strong>定义向量中单个元素包含三个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>0.99</td><td>0.99</td><td>0.99</td><td>316542</td></tr><tr><td>恶意请求</td><td>0.82</td><td>0.85</td><td>0.84</td><td>11084</td></tr><tr><td>avg / total</td><td>0.99</td><td>0.99</td><td>0.99</td><td>327626</td></tr></tbody></table><p>模型的准确度:0.9887066350045479</p><h4 id="定义向量中单个元素包含四个字符-2"><a href="#定义向量中单个元素包含四个字符-2" class="headerlink" title="定义向量中单个元素包含四个字符"></a><strong>定义向量中单个元素包含四个字符</strong></h4><p>正常请求数目: 1265974 恶意请求数目: 44530</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>正常请求</td><td>0.99</td><td>0.99</td><td>0.99</td><td>316542</td></tr><tr><td>恶意请求</td><td>0.78</td><td>0.81</td><td>0.80</td><td>11084</td></tr><tr><td>avg / total</td><td>0.99</td><td>0.99</td><td>0.99</td><td>327626</td></tr></tbody></table><p>模型的准确度:0.9858619279300178</p><h3 id="评估总结"><a href="#评估总结" class="headerlink" title="评估总结"></a><strong>评估总结</strong></h3><p>通过对比发现，使用svm支持向量机方法，并且向量中单个元素包含三个字符时训练的模型，在精确率、召回率、F1值上均表现出了较好的性能。</p><p>但是后期，在进行模型的基本测试时，本文发现使用svm支持向量机方法训练的模型将一些明显正常的url预测为恶意url，推测可能是过拟合或者数据集不够全面导致</p><p>svm支持向量机模型均认为以下url为恶意url（两个正常url，字符型sql注入绕过和sql联合注入）</p><table><thead><tr><th><em><strong>*明显是正常url*</strong></em></th><th><em><strong>*明显是恶意url*</strong></em></th></tr></thead><tbody><tr><td>foo.com?id=1</td><td>foo.com?id=1’or 1=1#</td></tr><tr><td>foo.com?id=2</td><td>foo.com?id=1’ union select database();%23</td></tr></tbody></table><p>而逻辑斯蒂回归模型则能够准确区分两者，例如（三个正常url，字符型sql注入绕过和数字型sql注入绕过以及sql联合注入）</p><table><thead><tr><th><em><strong>*常见的正常url*</strong></em></th><th><em><strong>*常见的恶意url*</strong></em></th></tr></thead><tbody><tr><td>foo.com?id=1</td><td>foo.com?id=1’or 1=1#</td></tr><tr><td>foo.com?id=2</td><td>foo.com?id=1 or 1=1%23</td></tr><tr><td>foo.com?id=abc</td><td>foo.com?id=1’ union select database();%23</td></tr></tbody></table><p>总的来说，逻辑斯蒂回归在不会发生过拟合影响基本判断的情况下，其准确率、召回率等并不低于svm支持向量机模型过多，是最理想的模型</p><h2 id="模型应用"><a href="#模型应用" class="headerlink" title="模型应用"></a><strong>模型应用</strong></h2><h3 id="完善脚本接口"><a href="#完善脚本接口" class="headerlink" title="完善脚本接口"></a><strong>完善脚本接口</strong></h3><p>由于sklearn的线程问题，无法直接将模型放入flask的路由函数中，故采用flask调用系统shell命令来执行脚本的方法进行替代。同时考虑到URL中可能出现空格以及其他命令行关键字，采用对传入的URL进行base64编码的方法解决该问题。</p><h3 id="使用flask编写restfulAPI对脚本进行调用"><a href="#使用flask编写restfulAPI对脚本进行调用" class="headerlink" title="使用flask编写restfulAPI对脚本进行调用"></a><strong>使用flask编写restfulAPI对脚本进行调用</strong></h3><p>flask负责通过接收指定路由上的POST数据得到原始URL值，然后对其base64编码，传递给命令行进行脚本调用，获得执行结果后将其传递回前端。</p><h2 id="项目完整代码"><a href="#项目完整代码" class="headerlink" title="项目完整代码"></a><strong>项目完整代码</strong></h2><h3 id="使用的python库"><a href="#使用的python库" class="headerlink" title="使用的python库"></a><strong>使用的python库</strong></h3><p>scikit-learn==0.19.2</p><p>numpy</p><p>Scipy</p><h3 id="逻辑斯蒂回归模型"><a href="#逻辑斯蒂回归模型" class="headerlink" title="逻辑斯蒂回归模型"></a><strong>逻辑斯蒂回归模型</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># coding: utf-8
import os

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import urllib
import pickle
import html

GRAM_BIT_NUM = 3


class lgs_net(object):

    def __init__(self):
        good_query_list = self.get_query_list('goodqueries.txt')
        bad_query_list = self.get_query_list('badqueries.txt')

        print('正常请求数目: ', len(good_query_list), '恶意请求数目: ', len(bad_query_list))

        good_y = [0 for i in range(0, len(good_query_list))]
        bad_y = [1 for i in range(0, len(bad_query_list))]

        queries = bad_query_list + good_query_list
        y = bad_y + good_y

        # 定义矢量化函数为 TF-IDF 矢量函数实例
        self.vectorizer = TfidfVectorizer(tokenizer=self.get_ngrams)

        # 把不规律的文本字符串列表转换成规律的 ( [i,j],tfidf值) 的矩阵X
        # 用于下一步训练分类器 lgs
        X = self.vectorizer.fit_transform(queries)

        # 使用 train_test_split 分割 X y 列表
        # X_train矩阵的数目对应 y_train列表的数目(一一对应)  --&gt;&gt; 用来训练模型
        # X_test矩阵的数目对应 	 (一一对应) --&gt;&gt; 用来测试模型的准确性
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

        # 定理逻辑回归方法模型
        self.lgs = LogisticRegression()

        # 使用逻辑回归方法训练模型实例 lgs
        self.lgs.fit(X_train, y_train)
        y_predict = self.lgs.predict(X_test)

        # 使用测试值 对 模型的准确度进行计算
        print('模型的准确度:{}'.format(self.lgs.score(X_test, y_test)))
        print(classification_report(y_test, y_predict, target_names=['正常请求', '恶意请求']))

    # 对 新的请求列表进行预测
    def predict(self, new_queries):
        new_queries = [urllib.parse.unquote(url) for url in new_queries]
        X_predict = self.vectorizer.transform(new_queries)
        res = self.lgs.predict(X_predict)
        res_list = []
        for q, r in zip(new_queries, res):
            tmp = '正常请求' if r == 0 else '恶意请求'
            q_entity = html.escape(q)
            res_list.append({'url': q_entity, 'res': tmp})
        return res_list

    # 得到文本中的请求列表
    def get_query_list(self, filename):
        directory = str(os.getcwd())
        filepath = directory + "/" + filename
        data = open(filepath, 'r', encoding='utf-8').readlines()
        query_list = []
        for d in data:
            d = str(urllib.parse.unquote(d))  # URL解码
            query_list.append(d)
        return list(set(query_list))

    # 生成特征向量, 每个特征含 GRAM_NUM 个字符
    def get_ngrams(self, query):
        tmp_query = str(query)
        ngrams = []
        for i in range(0, len(tmp_query) - GRAM_BIT_NUM):
            ngrams.append(tmp_query[i:i + GRAM_BIT_NUM])
        return ngrams


if __name__ == '__main__':
    # 若 模型文件 lgs.pkl 不存在,需要先训练出模型
    model = lgs_net()
    with open('lgs.pkl', 'wb') as output:
        pickle.dump(model, output)

    # 若 模型文件 lgs.pkl 已存在,则注释上述训练模型的代码,开启下列代码
    with open('lgs.pkl', 'rb') as f:
        model = pickle.load(f)
    model.predict(['www.foo.com/id=1&lt;script&gt;alert(1)&lt;/script&gt;', 'www.foo.com/name=admin\' or 1=1', 'abc.com/admin.php',
               '"&gt;&lt;svg onload=confirm(1)&gt;', 'test/q=&lt;a href="javascript:confirm(1)&gt;', 'q=../etc/passwd'])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="svm支持向量机模型"><a href="#svm支持向量机模型" class="headerlink" title="svm支持向量机模型"></a><strong>svm支持向量机模型</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># coding: utf-8
import os

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report
import urllib
import pickle
import html

GRAM_BIT_NUM = 3


class svm_net(object):

    def __init__(self):
        good_query_list = self.get_query_list('goodqueries.txt')
        bad_query_list = self.get_query_list('badqueries.txt')

        print('正常请求数目: ', len(good_query_list), '恶意请求数目: ', len(bad_query_list))

        good_y = [0 for i in range(0, len(good_query_list))]
        bad_y = [1 for i in range(0, len(bad_query_list))]

        queries = bad_query_list + good_query_list
        y = bad_y + good_y

        # 定义矢量化函数为 TF-IDF 矢量函数实例
        self.vectorizer = TfidfVectorizer(tokenizer=self.get_ngrams)

        # 把不规律的文本字符串列表转换成规律的 ( [i,j],tfidf值) 的矩阵X
        # 用于下一步训练分类器 svm
        X = self.vectorizer.fit_transform(queries)

        # 使用 train_test_split 分割 X y 列表
        # X_train矩阵的数目对应 y_train列表的数目(一一对应)  --&gt;&gt; 用来训练模型
        # X_test矩阵的数目对应 	 (一一对应) --&gt;&gt; 用来测试模型的准确性
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

        # 确定svm支持向量机方法模型
        self.svm = LinearSVC()

        # 使用svm支持向量机方法训练模型实例 svm
        self.svm.fit(X_train, y_train)
        y_predict = self.svm.predict(X_test)

        # 使用测试值 对 模型的准确度进行计算
        print('模型的准确度:{}'.format(self.svm.score(X_test, y_test)))
        print(classification_report(y_test, y_predict, target_names=['正常请求', '恶意请求']))

    # 对 新的请求列表进行预测
    def predict(self, new_queries):
        new_queries = [urllib.parse.unquote(url) for url in new_queries]
        X_predict = self.vectorizer.transform(new_queries)
        res = self.svm.predict(X_predict)
        res_list = []
        for q, r in zip(new_queries, res):
            tmp = '正常请求' if r == 0 else '恶意请求'
            q_entity = html.escape(q)
            res_list.append({'url': q_entity, 'res': tmp})
        return res_list

    # 得到文本中的请求列表
    def get_query_list(self, filename):
        directory = str(os.getcwd())
        filepath = directory + "/" + filename
        data = open(filepath, 'r', encoding='utf-8').readlines()
        query_list = []
        for d in data:
            d = str(urllib.parse.unquote(d))  # URL解码
            query_list.append(d)
        return list(set(query_list))

    # 生成特征向量, 每个特征含 GRAM_NUM 个字符
    def get_ngrams(self, query):
        tmp_query = str(query)
        ngrams = []
        for i in range(0, len(tmp_query) - GRAM_BIT_NUM):
            ngrams.append(tmp_query[i:i + GRAM_BIT_NUM])
        return ngrams


if __name__ == '__main__':
    # 若 模型文件 svm.pkl 不存在,需要先训练出模型
    model = svm_net()
    with open('svm.pkl', 'wb') as output:
        pickle.dump(model, output)

    # 若 模型文件 svm.pkl 已存在,则注释上述训练模型的代码,开启下列代码
    with open('svm.pkl', 'rb') as f:
        model = pickle.load(f)
    model.predict(['www.foo.com/id=1&lt;script&gt;alert(1)&lt;/script&gt;', 'www.foo.com/name=admin\' or 1=1', 'abc.com/admin.php',
               '"&gt;&lt;svg onload=confirm(1)&gt;', 'test/q=&lt;a href="javascript:confirm(1)&gt;', 'q=../etc/passwd'])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="朴素贝叶斯模型"><a href="#朴素贝叶斯模型" class="headerlink" title="朴素贝叶斯模型"></a><strong>朴素贝叶斯模型</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># coding: utf-8
import os

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report
import urllib
import pickle
import html

GRAM_BIT_NUM = 3


class bys_net(object):

    def __init__(self):
        good_query_list = self.get_query_list('goodqueries.txt')
        bad_query_list = self.get_query_list('badqueries.txt')

        print('正常请求数目: ', len(good_query_list), '恶意请求数目: ', len(bad_query_list))

        good_y = [0 for i in range(0, len(good_query_list))]
        bad_y = [1 for i in range(0, len(bad_query_list))]

        queries = bad_query_list + good_query_list
        y = bad_y + good_y

        # 定义矢量化函数为 TF-IDF 矢量函数实例
        self.vectorizer = TfidfVectorizer(tokenizer=self.get_ngrams)

        # 把不规律的文本字符串列表转换成规律的 ( [i,j],tfidf值) 的矩阵X
        # 用于下一步训练分类器 bys
        X = self.vectorizer.fit_transform(queries)

        # 使用 train_test_split 分割 X y 列表
        # X_train矩阵的数目对应 y_train列表的数目(一一对应)  --&gt;&gt; 用来训练模型
        # X_test矩阵的数目对应 	 (一一对应) --&gt;&gt; 用来测试模型的准确性
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

        # 确定朴素贝叶斯方法模型
        self.mnb = MultinomialNB()

        # 使用朴素贝叶斯方法训练模型实例 bys
        self.mnb.fit(X_train, y_train)
        y_predict = self.mnb.predict(X_test)

        # 使用测试值 对 模型的准确度进行计算
        print('模型的准确度:{}'.format(self.mnb.score(X_test, y_test)))
        print(classification_report(y_test, y_predict, target_names=['正常请求', '恶意请求']))

    # 对 新的请求列表进行预测
    def predict(self, new_queries):
        new_queries = [urllib.parse.unquote(url) for url in new_queries]
        X_predict = self.vectorizer.transform(new_queries)
        res = self.mnb.predict(X_predict)
        res_list = []
        for q, r in zip(new_queries, res):
            tmp = '正常请求' if r == 0 else '恶意请求'
            q_entity = html.escape(q)
            res_list.append({'url': q_entity, 'res': tmp})
        return res_list

    # 得到文本中的请求列表
    def get_query_list(self, filename):
        directory = str(os.getcwd())
        filepath = directory + "/" + filename
        data = open(filepath, 'r', encoding='utf-8').readlines()
        query_list = []
        for d in data:
            d = str(urllib.parse.unquote(d))  # URL解码
            query_list.append(d)
        return list(set(query_list))

    # 生成特征向量, 每个特征含 GRAM_NUM 个字符
    def get_ngrams(self, query):
        tmp_query = str(query)
        ngrams = []
        for i in range(0, len(tmp_query) - GRAM_BIT_NUM):
            ngrams.append(tmp_query[i:i + GRAM_BIT_NUM])
        return ngrams


if __name__ == '__main__':
    # 若 模型文件 bys.pkl 不存在,需要先训练出模型
    model = bys_net()
    with open('bys.pkl', 'wb') as output:
        pickle.dump(model, output)

    # 若 模型文件 bys.pkl 已存在,则注释上述训练模型的代码,开启下列代码
    with open('bys.pkl', 'rb') as f:
        model = pickle.load(f)
    model.predict(['www.foo.com/id=1&lt;script&gt;alert(1)&lt;/script&gt;', 'www.foo.com/name=admin\' or 1=1', 'abc.com/admin.php',
               '"&gt;&lt;svg onload=confirm(1)&gt;', 'test/q=&lt;a href="javascript:confirm(1)&gt;', 'q=../etc/passwd'])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="flask装载svm支持向量机模型的微型WAF"><a href="#flask装载svm支持向量机模型的微型WAF" class="headerlink" title="flask装载svm支持向量机模型的微型WAF"></a><strong>flask装载svm支持向量机模型的微型WAF</strong></h3><p>该flask服务由flask入口app.py、训练/预测脚本url_detect.py、模型文件svm.pkl以及数据集goodqueries.txt、badqueries.txt五部分组成</p><h4 id="app-py"><a href="#app-py" class="headerlink" title="app.py"></a><strong>app.py</strong></h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">import base64
import os

from flask import Flask, request

app = Flask(__name__)


@app.route('/', methods=['POST'])
def url_detect():
    if request.method == 'POST':
        try:
            url = request.form.get('url')
            url_b64 = str(base64.b64encode(bytes(url, encoding='utf-8')))[2:-1]
            result = os.popen('python3 url_detect.py ' + url_b64)
            return result.read()
        except:
            return "500 Internal Server Error"


if __name__ == '__main__':
app.run(host="0.0.0.0")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="url-detect-py"><a href="#url-detect-py" class="headerlink" title="url_detect.py"></a><strong>url_detect.py</strong></h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"># encoding: utf-8
import os
import sys
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report
import urllib
import pickle
import html
import base64
import warnings

warnings.filterwarnings('ignore')

GRAM_BIT_NUM = 3

class lgs_net(object):

    def __init__(self):
        good_query_list = self.get_query_list('goodqueries.txt')
        bad_query_list = self.get_query_list('badqueries.txt')

        print('正常请求数目: ', len(good_query_list), '恶意请求数目: ', len(bad_query_list))

        good_y = [0 for i in range(0, len(good_query_list))]
        bad_y = [1 for i in range(0, len(bad_query_list))]

        queries = bad_query_list + good_query_list
        y = bad_y + good_y

        # 定义矢量化函数为 TF-IDF 矢量函数实例
        self.vectorizer = TfidfVectorizer(tokenizer=self.get_ngrams)

        # 把不规律的文本字符串列表转换成规律的 ( [i,j],tfidf值) 的矩阵X
        # 用于下一步训练分类器 svm
        X = self.vectorizer.fit_transform(queries)

        # 使用 train_test_split 分割 X y 列表
        # X_train矩阵的数目对应 y_train列表的数目(一一对应)  --&gt;&gt; 用来训练模型
        # X_test矩阵的数目对应 	 (一一对应) --&gt;&gt; 用来测试模型的准确性
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

        # 确定svm支持向量机方法模型
        self.lgs = LinearSVC()

        # 使用svm支持向量机方法训练模型实例 svm
        self.lgs.fit(X_train, y_train)
        y_predict = self.lgs.predict(X_test)

        # 使用测试值 对 模型的准确度进行计算
        print('模型的准确度:{}'.format(self.lgs.score(X_test, y_test)))
        print(classification_report(y_test, y_predict, target_names=['正常请求', '恶意请求']))

    # 得到文本中的请求列表
    def get_query_list(self, filename):
        directory = str(os.getcwd())
        filepath = directory + "/" + filename
        data = open(filepath, 'r', encoding='utf-8').readlines()
        query_list = []
        for d in data:
            d = str(urllib.parse.unquote(d))  # URL解码
            query_list.append(d)
        return list(set(query_list))

    # 生成特征向量, 每个特征含 GRAM_BIT_NUM 个字符
    def get_ngrams(self, query):
        tmp_query = str(query)
        ngrams = []
        for i in range(0, len(tmp_query) - GRAM_BIT_NUM):
            ngrams.append(tmp_query[i:i + GRAM_BIT_NUM])
        return ngrams

    # 对新的请求列表进行预测
    def predict(self, new_queries):
        new_queries = [urllib.parse.unquote(str(url)) for url in new_queries]
        X_predict = self.vectorizer.transform(new_queries)
        res = self.lgs.predict(X_predict)
        res_list = []
        for q, r in zip(new_queries, res):
            res = 'good query' if r == 0 else 'bad query'
            q_entity = html.escape(q)
            res_list.append({'url': str(q_entity)[7:-6], 'res': res})
        print(res_list)
        return res_list


if __name__ == '__main__':
    # 若 模型文件 svm.pkl 不存在,需要先训练出模型
    # model = lgs_net()
    # with open('svm.pkl', 'wb') as output:
    #     pickle.dump(model, output)

    # 若 模型文件 svm.pkl 已存在,则注释上述训练模型的代码,开启下列代码
    url = sys.argv[1]
    url = base64.b64decode(bytes(str(url), encoding='utf-8'))
    with open('lgs.pkl', 'rb') as input:
        model = pickle.load(input)
    model.predict([url])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><hr><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.88rem}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22ab38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019fe8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fa fa-close"></i></a><h4 class="reward-title">欢迎投喂~</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div></div><script src="/libs/share/js/social-share.min.js"></script><div class="reprint" id="reprint-statement"><p class="reprint-tip"><i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp; <span>转载规则</span></p><div class="center-align"><a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh"><img alt="" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a></div><br><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">《python数据分析大作业（三）——机器学习的微型WAF》 </span>由 <a xmlns:cc="http://creativecommons.org/ns#" href="/2022/08/30/python-shu-ju-fen-xi-da-zuo-ye-san-ji-qi-xue-xi-de-wei-xing-waf/" property="cc:attributionName" rel="cc:attributionURL">xhsioi </a>采用 <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">知识共享署名 4.0 国际许可协议 </a>进行许可。</div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fa fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2022/10/03/ruan-jian-gong-cheng-ji-yu-hua-wei-yun-ping-tai-de-feng-huang-shang-cheng-xiang-mu-shi-xi-bao-gao/"><div class="card-image"><img src="/medias/featureimages/0.jpg" class="responsive-img" alt="软件工程——基于华为云平台的凤凰商城项目实习报告"> <span class="card-title">软件工程——基于华为云平台的凤凰商城项目实习报告</span></div></a><div class="card-content article-content"><div class="summary block-with-text">注意：这里没有提供截图，在学期末会在文中上传pdf版本报告。 持续规划与设计敏捷项目规划首先登录华为云官网，进入控制台内的规定区域，搜索DevCloud并登陆，单击页面上方右侧＂新建项目＂。在弹窗中选择＂DevOps全流程样例项目＂，输入项</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2022-10-03 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/" class="post-category" target="_blank">软件工程</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0/" target="_blank"><span class="chip bg-color">日常学习</span> </a><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E9%A1%B9%E7%9B%AE/" target="_blank"><span class="chip bg-color">项目</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fa fa-chevron-right"></i></div><div class="card"><a href="/2022/08/30/python-shu-ju-fen-xi-da-zuo-ye-er/"><div class="card-image"><img src="/medias/featureimages/1.jpg" class="responsive-img" alt="python数据分析大作业（二）"> <span class="card-title">python数据分析大作业（二）</span></div></a><div class="card-content article-content"><div class="summary block-with-text">作业二实验报告重要的库import requests from bs4 import BeautifulSoup import os import pandas as pd import random from pyecharts imp</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2022-08-30 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" class="post-category" target="_blank">大作业</a></span></div></div><div class="card-action article-tags"><a href="/tags/python/" target="_blank"><span class="chip bg-color">python</span> </a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BC%8C%E7%88%AC%E8%99%AB/" target="_blank"><span class="chip bg-color">数据分析，爬虫</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: cout>>.<<cin<br />作者: xhsioi<br />链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fa fa-list"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><footer class="page-footer bg-color"><div class="container row center-align"><div class="col s12 m8 l8 copy-right">&nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp; <span class="white-color">73.1k</span><br><span id="sitetime"></span><br><span id="busuanzi_container_site_pv" style="display:none"><i class="fa fa-heart-o"></i> 本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span> </span><span id="busuanzi_container_site_uv" style="display:none">人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.</span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fa fa-github"></i> </a><a href="mailto:m18846242315@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa fa-envelope-open"></i> </a><a href="https://zhihu.com/people/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-inverse">知</i> </a><a href="http://wpa.qq.com/msgrd?v=3&uin=2848220300&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2021,10,5,12,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><link rel="stylesheet" href="/css/prism.css"><script src="/js/prism.js" async></script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fa fa-angle-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script type="text/javascript">var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="Σ(っ °Д °;)っ你给我回来李和鑫！",clearTimeout(st)):(document.title="φ(゜▽゜*)♪你回来辣！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/miku.model.json"},display:{superSample:2,position:"left",width:150,height:300,hOffset:30,vOffset:-30},mobile:{show:!0,scale:.6},react:{opacity:.7},name:{canvas:"live2dcanvas",div:"live2d-widget"},dev:{border:!1},dialog:{enable:!0,hitokoto:!0}})</script></body></html>