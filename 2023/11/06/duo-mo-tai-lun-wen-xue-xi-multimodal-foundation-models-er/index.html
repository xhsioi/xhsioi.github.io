<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="多模态论文学习——Multimodal Foundation Models（二）, cout&gt;&gt;.&lt;&lt;cin"><meta name="baidu-site-verification" content="fmlEuI34ir"><meta name="google-site-verification" content="yCy2azpds5XSuGZvis6OuA-XIGF5GuGpYRAaGfD6o48"><meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7"><meta name="description" content=" 多模态论文学习——Multimodal Foundation Models（二）
这一部分我们着重分析第三章内容，即视觉生成相关的技术前沿。视觉生成常用于图像、视频以及神经辐射场、3D点云等等，这里我们主要针对其在AIGC领域的发展。文本"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>多模态论文学习——Multimodal Foundation Models（二） | cout&gt;&gt;.&lt;&lt;cin</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><style type="text/css"></style><script src="/libs/jquery/jquery-2.2.0.min.js"></script><script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ce84511d3df71640a9378a69f6293044";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script>document.write('<script src="https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba" id="sozz"><\/script>')</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 5.4.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">cout>>.<<cin</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a><ul class="right"><li class="hide-on-med-and-down"><a href="/" class="waves-effect waves-light"><i class="fa fa-home"></i> <span>首页</span></a></li><li class="hide-on-med-and-down"><a href="/tags" class="waves-effect waves-light"><i class="fa fa-tags"></i> <span>标签</span></a></li><li class="hide-on-med-and-down"><a href="/categories" class="waves-effect waves-light"><i class="fa fa-bookmark"></i> <span>分类</span></a></li><li class="hide-on-med-and-down"><a href="/archives" class="waves-effect waves-light"><i class="fa fa-archive"></i> <span>归档</span></a></li><li class="hide-on-med-and-down"><a href="/about" class="waves-effect waves-light"><i class="fa fa-user-circle-o"></i> <span>关于</span></a></li><li class="hide-on-med-and-down"><a href="/friends" class="waves-effect waves-light"><i class="fa fa-address-book"></i> <span>友情链接</span></a></li><li class="hide-on-med-and-down"><a href="/contact" class="waves-effect waves-light"><i class="fa fa-comments"></i> <span>Contact</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fa fa-search" title="搜索"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">cout>>.<<cin</div><div class="logo-desc">大连理工大学|软件工程|创中</div></div><ul class="menu-list mobile-menu-list"><li><a href="/" class="waves-effect waves-light"><i class="fa fa-fw fa-home"></i> 首页</a></li><li><a href="/tags" class="waves-effect waves-light"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li><a href="/categories" class="waves-effect waves-light"><i class="fa fa-fw fa-bookmark"></i> 分类</a></li><li><a href="/archives" class="waves-effect waves-light"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li><a href="/about" class="waves-effect waves-light"><i class="fa fa-fw fa-user-circle-o"></i> 关于</a></li><li><a href="/friends" class="waves-effect waves-light"><i class="fa fa-fw fa-address-book"></i> 友情链接</a></li><li><a href="/contact" class="waves-effect waves-light"><i class="fa fa-fw fa-comments"></i> Contact</a></li><li><div class="divider"></div></li><li><a href="https://github.com/xhsioi/xhsioi.github.io" class="waves-effect waves-light" target="_blank"><i class="fa fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/xhsioi/xhsioi.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/16.jpg)"><div class="container"><div class="row"><div class="col s12 m12 l12"><div class="brand"><div class="description center-align post-title">多模态论文学习——Multimodal Foundation Models（二）</div></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px}#toc-content .is-active-link{color:#42b983}#toc-content .is-active-link::before{background-color:#42b983}#floating-toc-btn{position:fixed;right:20px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" target="_blank"><span class="chip bg-color">论文研读</span> </a><a href="/tags/%E7%BB%BC%E8%BF%B0/" target="_blank"><span class="chip bg-color">综述</span> </a><a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" target="_blank"><span class="chip bg-color">多模态</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category" target="_blank">论文</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-11-06</div><div class="post-author info-break-policy"><i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp; xhsioi</div><div class="info-break-policy"><i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp; 1.7k</div><div class="info-break-policy"><i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp; 6 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="多模态论文学习multimodal-foundation-models二"><a class="markdownIt-Anchor" href="#多模态论文学习multimodal-foundation-models二"></a> 多模态论文学习——Multimodal Foundation Models（二）</h1><p>这一部分我们着重分析第三章内容，即视觉生成相关的技术前沿。视觉生成常用于图像、视频以及神经辐射场、3D点云等等，这里我们主要针对其在AIGC领域的发展。文本条件（如类标签、文本、边界框、布局掩码等等）对图像生成产生了十分深远的影响。</p><ul><li>T2I的发展现状与局限性；</li><li>加强T2I代对齐的目标领域：<ul><li>空间可控T2I生成；</li><li>基于文本的图像编辑；</li><li>进一步遵循文本提示的图像生成；</li><li>T2I的概念定制；</li></ul></li></ul><h2 id="相关知识"><a class="markdownIt-Anchor" href="#相关知识"></a> 相关知识</h2><h3 id="ai-alignments"><a class="markdownIt-Anchor" href="#ai-alignments"></a> AI Alignments</h3><p>AI对齐要求ai系统的目标要和人类的价值观与利益对齐，保持一致。目前存在以下三个问题：</p><ul><li>选择合适的价值观；</li><li>将价值观编码成为ai系统；</li><li>选择合适的数据进行训练；</li></ul><p>在前期缺乏ai对齐的条件下，出现了寻找系统bug实现博弈最优解、多种设定目标冲突时做出错误取舍等问题。目前，Openai推出的InstructGPT预训练模型使用了人类反馈的强化学习技术，将人类的表现作为奖励信号，从而实现prompt tuning。</p><h3 id="扩散模型相关论文"><a class="markdownIt-Anchor" href="#扩散模型相关论文"></a> 扩散模型相关论文：</h3><p>(Sohl-Dickstein et al., 2015; Song and Ermon, 2020; Ho et al.,2020)</p><p>stable difusion：(Rombach et al., 2022)</p><h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2><h3 id="human-alignments-in-visual-generation"><a class="markdownIt-Anchor" href="#human-alignments-in-visual-generation"></a> <strong>Human Alignments in Visual Generation</strong></h3><p>ai对齐研究致力于遵循人类的意图来合成所需生成的视觉内容，目前的文献都在关注于简单T2I模型的某一特定缺点上：</p><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202311061336966.png" alt=""></p><ul><li>空间可控的T2I生成：将文本输入与其他条件结合，从而使得视觉生成的空间位置更加可控（Yanget al., 2023b; Li et al., 2023n; Zhang and Agrawala, 2023）</li><li>基于文本的图像编辑：从局部修改对象到调整全局的图像风格。(Brooks et al., 2023)</li><li>更好地遵循文本提示：普通的T2I模型可能会忽略某些文本描述，生成与输入文本不完全对应的图像，对此给出了改进的方法。(Feng et al., 2022b; Black et al., 2023)</li><li>视觉概念定制：在不同的环境中生成特定特征的图像，通过专门的token embedding或者conditioned image实现定制的模型 。(Ruiz et al., 2023; Chen et al., 2023f)</li></ul><h3 id="t2i发展历程"><a class="markdownIt-Anchor" href="#t2i发展历程"></a> T2I发展历程</h3><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202311061347276.png" alt=""></p><p>输入：文本;</p><p>输出：成对的图像作为输出；</p><p>技术：</p><ul><li>GAN：生成器和辨别器，二者相互竞争：生成器结合输入和噪声合成与语义相关的图像；辨别其对真实和合成图像进行区分；</li><li>VAE：成对的编码器和解码器生成图像：编码器网络将图像的编码进行潜在表示，解码器实现潜在表示到图像的转化。目前的工作集中于：<ul><li>对编码潜在空间进行正则化；</li><li>将潜在表示更加离散化；</li></ul></li><li>**Discrete image token prediction：**这个之前没有了解过，主要原理是成对的图像标记器和去标记器的组合，工作有VQGAN以及令牌预测等策略。之后可以了解一下。</li><li><strong>diffusion model：利用完全随机的图像来启动，在每次迭代预测之后去除一个噪声元素； (Sohl-Dickstein et al., 2015; Song and Ermon, 2020; Ho et al.,2020)</strong></li></ul><p>**下面对最广泛的开源T2I，即基于交叉注意力机制的文本图像融合Stable Diffusion进行介绍。**其主要构成是一个图像VAE、一个去噪的U-NET以及一个条件编码器。</p><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202311061408008.png" alt=""></p><ul><li>VAE：将原始图像转换为潜在表示，在去噪的同时压缩潜空间，从而显著提高运算效率；</li><li>条件编码器：SD使用CLIP文本编辑器将输入文本转化为文本特征；</li><li>去噪U-Net：预测噪声，在每一次迭代之后去除该噪声，从而逐步将初始随机噪声演化为有意义的潜在图像；需要注意的是，在U-Net中的每个上下采样木块都有一个交叉注意力层和一个二维卷积层；</li></ul><h2 id="spatial-controllable-generation"><a class="markdownIt-Anchor" href="#spatial-controllable-generation"></a> <strong>Spatial Controllable Generation</strong></h2><p>采用额外的空间输入条件来指导图像的生成。</p><ul><li>将普通T2I模型中的图像级文本描述扩展到基于区域的文本描述，ReCo是这个方向上最具有代表性的模型。</li><li>从box扩展到基于二维数组表示的密集空间：segmentation masks、边缘图和深度图等等，就是将额外的密集条件和视觉潜在性一起作为输入，然后进行训练的降采样初始化；<ul><li>在ControlNet分支的输出合并回采样快之前，构建一个1×1的卷积层作为门控连接器，逐渐将额外的条件注入到预先训练好的SD中；（Zhang, L. and Agrawala, M. (2023). Adding conditional control to text-to-image diffusion models.<em>arXiv preprint arXiv:2302.05543</em>.）</li></ul></li><li>不进行微调的空间控制：</li></ul><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202311061435240.png" alt=""></p><h2 id="text-based-editing"><a class="markdownIt-Anchor" href="#text-based-editing"></a> <strong>Text-based Editing</strong></h2><p>关注于图像中的特定对象更改。</p><ul><li><p>改变局部区域，或者在某个区域中添加一个对象：扩散模型中的逐步去噪一定程度上对应了图像编辑，这一部分主要关注对交叉注意力层的处理。</p><ul><li>随机微分编辑：</li><li>混合潜在扩散：</li></ul></li><li><p>从空间编辑扩展到语言输入描述空间区域，给出期望的外观：输入的文本作为指令进行图像生成。目前最主要的问题是图和生成成对的编辑数据：</p><ul><li><p>LMM方法：（Brooks, T., Holynski, A., and Efros, A. A. (2023 Instructpix2pix: Learning to follow image editing instructions. <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern</em></p><p><em>Recognition</em>, pages 18392–18402.）</p></li><li><p>Promt2提示：（Hertz, A., Mokady, R., Tenenbaum, J., Aberman, K., Pritch, Y., and Cohen-or, D. (2022). Prompt</p><p>to-prompt image editing with cross-attention control. In <em>The Eleventh International Conference</em></p><p><em>on Learning Representations</em>.）</p></li><li><p>CM3Leon：（Wu, C., Yin, S., Qi, W., Wang, X., Tang, Z., and Duan, N. (2023a). Visual chatgpt: Talking, drawing</p><p>and editing with visual foundation models. <em>arXiv preprint arXiv:2303.04671</em>.）</p></li></ul></li><li><p>系统集成不同的专门模块生成；使用外部预先训练的模型进行编辑；</p><ul><li><p>VisualChatGPT：（Wu, C., Yin, S., Qi, W., Wang, X., Tang, Z., and Duan, N. (2023a). Visual chatgpt: Talking, drawing</p><p>and editing with visual foundation models. <em>arXiv preprint arXiv:2303.04671</em>.）</p></li></ul></li></ul><h2 id="text-prompts-following"><a class="markdownIt-Anchor" href="#text-prompts-following"></a> <strong>Text Prompts Following</strong></h2><p>当文本输入较为复杂时，生成图像的过程中可能忽略了部分特征。这里关注点在于交叉注意力层的重构以及图像文本相似性的正则计算。</p><ul><li>重新分配潜在表达和图像-文本交叉注意，使更多的文本名词短语保存在图像中；</li><li>以图像-文本相似性作为惩罚；</li></ul></div><hr><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.88rem}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22ab38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019fe8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fa fa-close"></i></a><h4 class="reward-title">欢迎投喂~</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div></div><script src="/libs/share/js/social-share.min.js"></script><div class="reprint" id="reprint-statement"><p class="reprint-tip"><i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp; <span>转载规则</span></p><div class="center-align"><a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh"><img alt="" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a></div><br><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">《多模态论文学习——Multimodal Foundation Models（二）》 </span>由 <a xmlns:cc="http://creativecommons.org/ns#" href="/2023/11/06/duo-mo-tai-lun-wen-xue-xi-multimodal-foundation-models-er/" property="cc:attributionName" rel="cc:attributionURL">xhsioi </a>采用 <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">知识共享署名 4.0 国际许可协议 </a>进行许可。</div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fa fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2023/11/08/tu-shen-jing-wang-luo-xue-xi/"><div class="card-image"><img src="/medias/featureimages/12.jpg" class="responsive-img" alt="图神经网络学习"> <span class="card-title">图神经网络学习</span></div></a><div class="card-content article-content"><div class="summary block-with-text">图神经网络学习 参考文献：https://distill.pub/2021/gnn-intro/ 前言 图神经网络的基本结构： 可以看到，在每一层传播之后图的基本结构没有发生变化，只对顶点、边以及全局信息进行了调整，也就是权重的变化。</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2023-11-08 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category" target="_blank">论文</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" target="_blank"><span class="chip bg-color">论文研读</span> </a><a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" target="_blank"><span class="chip bg-color">图神经网络</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fa fa-chevron-right"></i></div><div class="card"><a href="/2023/11/02/duo-mo-tai-lun-wen-xue-xi-multimodal-foundation-models/"><div class="card-image"><img src="/medias/featureimages/6.jpg" class="responsive-img" alt="多模态论文学习——Multimodal Foundation Models（一）"> <span class="card-title">多模态论文学习——Multimodal Foundation Models（一）</span></div></a><div class="card-content article-content"><div class="summary block-with-text">多模态论文学习——Multimodal Foundation Models（一） 第一遍阅读 Abstract 本文关注于多模态基础模型的发展，根据领域发展是否成熟分成两类分别进行探讨： 成熟：通过学习vision backbones</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2023-11-02 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category" target="_blank">论文</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" target="_blank"><span class="chip bg-color">论文研读</span> </a><a href="/tags/%E7%BB%BC%E8%BF%B0/" target="_blank"><span class="chip bg-color">综述</span> </a><a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" target="_blank"><span class="chip bg-color">多模态</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: cout>>.<<cin<br />作者: xhsioi<br />链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fa fa-list"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><footer class="page-footer bg-color"><div class="container row center-align"><div class="col s12 m8 l8 copy-right">&nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp; <span class="white-color">109.5k</span><br><span id="sitetime"></span><br><span id="busuanzi_container_site_pv" style="display:none"><i class="fa fa-heart-o"></i> 本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span> </span><span id="busuanzi_container_site_uv" style="display:none">人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.</span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fa fa-github"></i> </a><a href="mailto:m18846242315@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa fa-envelope-open"></i> </a><a href="https://zhihu.com/people/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-inverse">知</i> </a><a href="http://wpa.qq.com/msgrd?v=3&uin=2848220300&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2021,10,5,12,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><link rel="stylesheet" href="/css/prism.css"><script src="/js/prism.js" async></script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fa fa-angle-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script type="text/javascript">var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="Σ(っ °Д °;)っ你给我回来李和鑫！",clearTimeout(st)):(document.title="φ(゜▽゜*)♪你回来辣！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/miku.model.json"},display:{superSample:2,position:"left",width:150,height:300,hOffset:30,vOffset:-30},mobile:{show:!0,scale:.6},react:{opacity:.7},name:{canvas:"live2dcanvas",div:"live2d-widget"},dev:{border:!1},dialog:{enable:!0,hitokoto:!0}})</script></body></html>