<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="InstructBLIP论文阅读, cout&gt;&gt;.&lt;&lt;cin"><meta name="baidu-site-verification" content="fmlEuI34ir"><meta name="google-site-verification" content="yCy2azpds5XSuGZvis6OuA-XIGF5GuGpYRAaGfD6o48"><meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7"><meta name="description" content=" InstructBLIP
代码地址：https://github.com/salesforce/LAVIS/tree/main/projects/instructblip
 前言
这里主要对其数据构建的方法进行深入的研究，同时对基座模型B"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>InstructBLIP论文阅读 | cout&gt;&gt;.&lt;&lt;cin</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><style type="text/css"></style><script src="/libs/jquery/jquery-2.2.0.min.js"></script><script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ce84511d3df71640a9378a69f6293044";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script>document.write('<script src="https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba" id="sozz"><\/script>')</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">cout>>.<<cin</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a><ul class="right"><li class="hide-on-med-and-down"><a href="/" class="waves-effect waves-light"><i class="fa fa-home"></i> <span>首页</span></a></li><li class="hide-on-med-and-down"><a href="/tags" class="waves-effect waves-light"><i class="fa fa-tags"></i> <span>标签</span></a></li><li class="hide-on-med-and-down"><a href="/categories" class="waves-effect waves-light"><i class="fa fa-bookmark"></i> <span>分类</span></a></li><li class="hide-on-med-and-down"><a href="/archives" class="waves-effect waves-light"><i class="fa fa-archive"></i> <span>归档</span></a></li><li class="hide-on-med-and-down"><a href="/about" class="waves-effect waves-light"><i class="fa fa-user-circle-o"></i> <span>关于</span></a></li><li class="hide-on-med-and-down"><a href="/friends" class="waves-effect waves-light"><i class="fa fa-address-book"></i> <span>友情链接</span></a></li><li class="hide-on-med-and-down"><a href="/contact" class="waves-effect waves-light"><i class="fa fa-comments"></i> <span>Contact</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fa fa-search" title="搜索"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">cout>>.<<cin</div><div class="logo-desc">大连理工大学|软件工程|创中</div></div><ul class="menu-list mobile-menu-list"><li><a href="/" class="waves-effect waves-light"><i class="fa fa-fw fa-home"></i> 首页</a></li><li><a href="/tags" class="waves-effect waves-light"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li><a href="/categories" class="waves-effect waves-light"><i class="fa fa-fw fa-bookmark"></i> 分类</a></li><li><a href="/archives" class="waves-effect waves-light"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li><a href="/about" class="waves-effect waves-light"><i class="fa fa-fw fa-user-circle-o"></i> 关于</a></li><li><a href="/friends" class="waves-effect waves-light"><i class="fa fa-fw fa-address-book"></i> 友情链接</a></li><li><a href="/contact" class="waves-effect waves-light"><i class="fa fa-fw fa-comments"></i> Contact</a></li><li><div class="divider"></div></li><li><a href="https://github.com/xhsioi/xhsioi.github.io" class="waves-effect waves-light" target="_blank"><i class="fa fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/xhsioi/xhsioi.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/4.jpg)"><div class="container"><div class="row"><div class="col s12 m12 l12"><div class="brand"><div class="description center-align post-title">InstructBLIP论文阅读</div></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px}#toc-content .is-active-link{color:#42b983}#toc-content .is-active-link::before{background-color:#42b983}#floating-toc-btn{position:fixed;right:20px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" target="_blank"><span class="chip bg-color">论文研读</span> </a><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" target="_blank"><span class="chip bg-color">多模态</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category" target="_blank">论文</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-12-07</div><div class="post-author info-break-policy"><i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp; xhsioi</div><div class="info-break-policy"><i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp; 1.5k</div><div class="info-break-policy"><i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp; 5 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="instructblip"><a class="markdownIt-Anchor" href="#instructblip"></a> InstructBLIP</h1><p>代码地址：<a target="_blank" rel="noopener" href="https://github.com/salesforce/LAVIS/tree/main/projects/instructblip">https://github.com/salesforce/LAVIS/tree/main/projects/instructblip</a></p><h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h2><p>这里主要对其数据构建的方法进行深入的研究，同时对基座模型BLIP-2进行了解，最后对源码进行分析。重点章节为Vision-Language Instruction Tuning。</p><h2 id="相关知识"><a class="markdownIt-Anchor" href="#相关知识"></a> 相关知识</h2><h3 id="held-in-and-held-out"><a class="markdownIt-Anchor" href="#held-in-and-held-out"></a> held-in and held-out</h3><p>前者代表用于训练模型的数据集，通常是原始数据集中随机抽取一部分数据；而后者用于评估模型性能、泛化能力。</p><h3 id="多模态数据集的构建方法"><a class="markdownIt-Anchor" href="#多模态数据集的构建方法"></a> 多模态数据集的构建方法</h3><p><strong>指令数据集：</strong></p><p>将现有的NLP数据集转换成指令格式来收集指令调整数据 [46, 7, 35, 45]或者LLM生成指令数据[2, 13, 44, 40]；生成的指令混合训练。</p><h3 id="blip"><a class="markdownIt-Anchor" href="#blip"></a> BLIP</h3><p>BLIP（Bootstrapping Language-Image Pretraining）：引入了跨模态的编码器和解码器，实现了跨模态信息流动。</p><p><strong>MED架构</strong></p><p>编码器-解码器的多模态混合结构MED，进行多任务预学习和迁移学习，其中包括两个单模态编码器、一个以图像为基础的编码器和一个以图像为基础的解码器。</p><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202312071848718.png" alt=""></p><p>首先分别对image和text进行encode，经过自注意力、前向传播后计算ITC损失（图像-文本对比损失，对齐图像和文本的潜在特征空间）。之后就是对比学习的过程，将text和image同时编码后计算ITM（对图文匹配性进行二分类，也就是正负样本的训练，建模图文多模态信息的相关性）。最后解码，通过交叉熵进行优化，训练模型自回归生成目标（LM损失）。</p><p><strong>CapFilt</strong></p><p>数据集中的数据集存在噪音以及无匹配图片的问题，因此引入了cationer和Filter进行处理：</p><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202312071907262.png" alt=""></p><p>Filter和caption都是通过预训练模型得到的，过滤存在噪音的IT对，同时生成缺失的text。</p><h3 id="blip-2"><a class="markdownIt-Anchor" href="#blip-2"></a> BLIP-2</h3><p>BLIP-2由预训练的image encoder、预训练的LLM，和一个可学习的Q-Former组成。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pretrained image encoder</span>
self<span class="token punctuation">.</span>vision_model <span class="token operator">=</span> Blip2VisionModel<span class="token punctuation">(</span>config<span class="token punctuation">.</span>vision_config<span class="token punctuation">)</span>
<span class="token comment"># input query</span>
self<span class="token punctuation">.</span>query_tokens <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> config<span class="token punctuation">.</span>num_query_tokens<span class="token punctuation">,</span> config<span class="token punctuation">.</span>qformer_config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>qformer <span class="token operator">=</span> Blip2QFormerModel<span class="token punctuation">(</span>config<span class="token punctuation">.</span>qformer_config<span class="token punctuation">)</span>

self<span class="token punctuation">.</span>language_projection <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>qformer_config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>text_config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
<span class="token keyword">if</span> config<span class="token punctuation">.</span>use_decoder_only_language_model<span class="token punctuation">:</span>
    language_model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span>config<span class="token punctuation">.</span>text_config<span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    language_model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span>config<span class="token punctuation">.</span>text_config<span class="token punctuation">)</span>
<span class="token comment"># pretrained large language model</span>
self<span class="token punctuation">.</span>language_model <span class="token operator">=</span> language_model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其模型的架构如下图所示：</p><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202312080834876.png" alt=""></p><p>需要注意的是，在1中出现的三种loss都发生了变化：</p><ul><li>ITC：采用了单模态的自注意力掩码，不允许Query和Text相互注意。具体来说就是计算每个Query的嵌入和text嵌入的相似度从而完成匹配；</li><li>ITG（Image-grounded Text Generation）：基于图像的文本生成。在Q-Former生成文本时，ITG采用多模态的注意力机制掩码来控制Query和Text的交互，Query可以相互关注，但是不能关注Text标记每个Text标记都可以处理所有Query以及前面的Text标记。</li><li>ITM：对比学习匹配过程。</li></ul><h3 id="prompt-tuninginstruction-tuningcot"><a class="markdownIt-Anchor" href="#prompt-tuninginstruction-tuningcot"></a> Prompt-Tuning,Instruction-Tuning,CoT</h3><p>prompt：特定任务中对预测结果进行mask（类似于bert）就是一种prompt方法，即利用LLM的生成能力帮我们完成任务，让模型输出我们想要的内容；</p><p>instruction：告诉模型如何处理数据或者执行某个操作，不是简单的上下文。其基本流程如下所示：</p><ul><li>准备自然语言指令集：描述任务类型和任务目标：“该文本的情感是正面还是负面的”；</li><li>训练数据集：标注正面和负面；</li><li>模型输入：指令和数据集拼接作为输入；</li><li>在指令上进行微调，满足特定任务；</li></ul><p>CoT：将生成任务分解成较小、相互关联的任务，帮助模型理解和生成连贯、上下文感知的响应。</p><h2 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h2><p>背景：额外的视觉指令对通用视觉语言模型具有一定挑战；</p><p>创新：基于BLIP-2模型对视觉语言指令调整进行研究。</p><ul><li>26个公开数据集，将其转换为指令调整格式；</li><li>指令感知查询转换器，根据给定的指令提取特征信息；</li></ul><p>结果：13个数据集实现zeroshot，下游任务表现较好；</p><h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2><p>本文的基座模型就是BLIP-2，其基本架构没有变化。</p><p>贡献：</p><ul><li><strong>对视觉语言指令调整进行了全面研究，将26个数据集转换为指令微调模式；</strong></li><li>文本指令不仅仅提供给LLM，也提供给Q-Former，使得其从冻结的图像编码器中提取指令感知的视觉特征；</li><li>LLM的使用：FlanT5、Viuna；</li></ul><h2 id="vision-language-instruction-tuning"><a class="markdownIt-Anchor" href="#vision-language-instruction-tuning"></a> Vision-Language Instruction Tuning</h2><p>在以下的数据集上都实现了指令微调；</p><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202312080918240.png" alt=""></p><p>小部分数据作为held-out评估模型最后的zeroshot性能。在指令微调过程中，对每个数据集统一混合所有训练集和样本指令；在场景文本中还会添加OCR标记作为补充信息。</p><h3 id="指令感知视觉特征提取"><a class="markdownIt-Anchor" href="#指令感知视觉特征提取"></a> 指令感知视觉特征提取</h3><p>背景：BLIP-2直接将静态的图像特征输入LLM，因此给出了改进：</p><p><img src="https://gcore.jsdelivr.net/gh/xhsioi/blog-img@main/img/202312080936599.png" alt=""></p><p>和BLIP-2不同的是，增加了指令和请求的自注意力计算过程，激励提取与任务相关的图像特征，将结果和图像嵌入进行交叉注意力计算；</p><h3 id="推断方法"><a class="markdownIt-Anchor" href="#推断方法"></a> 推断方法</h3><p>直接提示经过指令调整的模型生成响应（生成任务）。对于分类任务，使用词汇排序法（限制生成答案数量，对数似然选择topk）、扩充正负样本标签等等。</p><h3 id="experiments"><a class="markdownIt-Anchor" href="#experiments"></a> Experiments</h3><p>在消融实验的过程中，发现在空间视觉推理或者时间视觉推理的数据集中，性能的下降更为严重；</p><p>BLIP相较于其他多模态模型，能够自适应调整生成文本的长度来满足用户的意图；</p><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><p>应用于复杂视觉推理、VQA、下游任务初始化。</p></div><hr><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.88rem}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22ab38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019fe8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fa fa-close"></i></a><h4 class="reward-title">欢迎投喂~</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div></div><script src="/libs/share/js/social-share.min.js"></script><div class="reprint" id="reprint-statement"><p class="reprint-tip"><i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp; <span>转载规则</span></p><div class="center-align"><a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh"><img alt="" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a></div><br><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">《InstructBLIP论文阅读》 </span>由 <a xmlns:cc="http://creativecommons.org/ns#" href="/2023/12/07/instructblip-lun-wen-yue-du/" property="cc:attributionName" rel="cc:attributionURL">xhsioi </a>采用 <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">知识共享署名 4.0 国际许可协议 </a>进行许可。</div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fa fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2023/12/15/mei-ri-yi-ti-zheng-li-2023-11/"><div class="card-image"><img src="/medias/featureimages/5.jpg" class="responsive-img" alt="每日一题整理——2023.11"> <span class="card-title">每日一题整理——2023.11</span></div></a><div class="card-content article-content"><div class="summary block-with-text">每日一题整理——2023.11 前言 这个月整理的题目比较少，一方面是偷懒了，另一方面就是以后只做中文站的题了，一天两道太浪费时间了。 题 11.4 Last Moment Before All Ants Fall Out of a</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2023-12-15 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/leetcode/" class="post-category" target="_blank">leetcode</a></span></div></div><div class="card-action article-tags"><a href="/tags/c/" target="_blank"><span class="chip bg-color">c++</span> </a><a href="/tags/%E7%AE%97%E6%B3%95/" target="_blank"><span class="chip bg-color">算法</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fa fa-chevron-right"></i></div><div class="card"><a href="/2023/12/05/shuang-liu-wang-luo-lun-wen-jing-du/"><div class="card-image"><img src="/medias/featureimages/9.jpg" class="responsive-img" alt="双流网络论文精读"> <span class="card-title">双流网络论文精读</span></div></a><div class="card-content article-content"><div class="summary block-with-text">双流网络论文精读 前言 这几天在看毕设相关的文献，突然发现对视频embedding的方法不是很熟悉，因此看了一下双流和I3D的相关工作。 Two-Stream Convolutional Networks for Action Rec</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2023-12-05 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category" target="_blank">论文</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" target="_blank"><span class="chip bg-color">论文研读</span> </a><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E5%8F%8C%E6%B5%81%E7%BD%91%E7%BB%9C/" target="_blank"><span class="chip bg-color">双流网络</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: cout>>.<<cin<br />作者: xhsioi<br />链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fa fa-list"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><footer class="page-footer bg-color"><div class="container row center-align"><div class="col s12 m8 l8 copy-right">&nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp; <span class="white-color">119k</span><br><span id="sitetime"></span><br><span id="busuanzi_container_site_pv" style="display:none"><i class="fa fa-heart-o"></i> 本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span> </span><span id="busuanzi_container_site_uv" style="display:none">人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.</span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fa fa-github"></i> </a><a href="mailto:m18846242315@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa fa-envelope-open"></i> </a><a href="https://zhihu.com/people/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-inverse">知</i> </a><a href="http://wpa.qq.com/msgrd?v=3&uin=2848220300&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2021,10,5,12,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><link rel="stylesheet" href="/css/prism.css"><script src="/js/prism.js" async></script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fa fa-angle-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script type="text/javascript">var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="Σ(っ °Д °;)っ你给我回来李和鑫！",clearTimeout(st)):(document.title="φ(゜▽゜*)♪你回来辣！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"superSample":2,"position":"left","width":150,"height":300,"hOffset":30,"vOffset":-30},"mobile":{"show":true,"scale":0.6},"react":{"opacity":0.7},"name":{"canvas":"live2dcanvas","div":"live2d-widget"},"dev":{"border":false},"dialog":{"enable":true,"hitokoto":true}});</script></body></html>