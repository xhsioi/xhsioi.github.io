<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note, cout&gt;&gt;.&lt;&lt;cin"><meta name="baidu-site-verification" content="fmlEuI34ir"><meta name="google-site-verification" content="yCy2azpds5XSuGZvis6OuA-XIGF5GuGpYRAaGfD6o48"><meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7"><meta name="description" content=" CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note
[TOC]
 相关背景
 Question Only Model（RUBi）
https://blog.cs"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note | cout&gt;&gt;.&lt;&lt;cin</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><style type="text/css"></style><script src="/libs/jquery/jquery-2.2.0.min.js"></script><script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ce84511d3df71640a9378a69f6293044";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script>document.write('<script src="https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba" id="sozz"><\/script>')</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 5.4.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">cout>>.<<cin</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a><ul class="right"><li class="hide-on-med-and-down"><a href="/" class="waves-effect waves-light"><i class="fa fa-home"></i> <span>首页</span></a></li><li class="hide-on-med-and-down"><a href="/tags" class="waves-effect waves-light"><i class="fa fa-tags"></i> <span>标签</span></a></li><li class="hide-on-med-and-down"><a href="/categories" class="waves-effect waves-light"><i class="fa fa-bookmark"></i> <span>分类</span></a></li><li class="hide-on-med-and-down"><a href="/archives" class="waves-effect waves-light"><i class="fa fa-archive"></i> <span>归档</span></a></li><li class="hide-on-med-and-down"><a href="/about" class="waves-effect waves-light"><i class="fa fa-user-circle-o"></i> <span>关于</span></a></li><li class="hide-on-med-and-down"><a href="/friends" class="waves-effect waves-light"><i class="fa fa-address-book"></i> <span>友情链接</span></a></li><li class="hide-on-med-and-down"><a href="/contact" class="waves-effect waves-light"><i class="fa fa-comments"></i> <span>Contact</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fa fa-search" title="搜索"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">cout>>.<<cin</div><div class="logo-desc">大连理工大学|软件工程|创中</div></div><ul class="menu-list mobile-menu-list"><li><a href="/" class="waves-effect waves-light"><i class="fa fa-fw fa-home"></i> 首页</a></li><li><a href="/tags" class="waves-effect waves-light"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li><a href="/categories" class="waves-effect waves-light"><i class="fa fa-fw fa-bookmark"></i> 分类</a></li><li><a href="/archives" class="waves-effect waves-light"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li><a href="/about" class="waves-effect waves-light"><i class="fa fa-fw fa-user-circle-o"></i> 关于</a></li><li><a href="/friends" class="waves-effect waves-light"><i class="fa fa-fw fa-address-book"></i> 友情链接</a></li><li><a href="/contact" class="waves-effect waves-light"><i class="fa fa-fw fa-comments"></i> Contact</a></li><li><div class="divider"></div></li><li><a href="https://github.com/xhsioi/xhsioi.github.io" class="waves-effect waves-light" target="_blank"><i class="fa fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/xhsioi/xhsioi.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/10.jpg)"><div class="container"><div class="row"><div class="col s12 m12 l12"><div class="brand"><div class="description center-align post-title">CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note</div></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px}#toc-content .is-active-link{color:#42b983}#toc-content .is-active-link::before{background-color:#42b983}#floating-toc-btn{position:fixed;right:20px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span> </a><a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" target="_blank"><span class="chip bg-color">论文研读</span> </a><a href="/tags/%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94/" target="_blank"><span class="chip bg-color">视觉问答</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category" target="_blank">论文</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-08-22</div><div class="post-author info-break-policy"><i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp; xhsioi</div><div class="info-break-policy"><i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp; 2.4k</div><div class="info-break-policy"><i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp; 8 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="cvpr2020-counterfactual-samples-synthesizing-for-robust-vqa-note"><a class="markdownIt-Anchor" href="#cvpr2020-counterfactual-samples-synthesizing-for-robust-vqa-note"></a> CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note</h1><p>[TOC]</p><h2 id="相关背景"><a class="markdownIt-Anchor" href="#相关背景"></a> 相关背景</h2><h3 id="question-only-modelrubi"><a class="markdownIt-Anchor" href="#question-only-modelrubi"></a> Question Only Model（RUBi）</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42305378/article/details/105809513">https://blog.csdn.net/weixin_42305378/article/details/105809513</a></p><p>常规的vqa处理中使用很多统计规律，计算答案出现的次数和问题中某些模态之间的统计规律。在本文中 question-only模型用于和传统的vqa计算进行比较，突出这种单模态模型存在的问题，提出了RUBi模型进行改进，主要改进就是在整体vqa顶层添加了一个问题模型，掩盖答案之后进行生成，从而减少正例的损失，增加反例的损失。</p><p>这就是本文提到的使用问题模型对模型进行正则化的过程，存在视觉解释性不足以及问题敏感性的缺点。</p><h3 id="lmh-model"><a class="markdownIt-Anchor" href="#lmh-model"></a> LMH Model</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/bxg1065283526/article/details/106163357">https://blog.csdn.net/bxg1065283526/article/details/106163357</a></p><p>常规vqa模型注重特定的关键词，不注重上下文关系问题，这篇文章首先训练了仅基于数据集偏差进行预测的朴素模型，然后将训练之后的模型和朴素模型进行拟合，生成鲁棒性更高的模型，该方法也是着重于对vqa的偏置项进行处理，提升反例对应的偏置，降低正例对应的偏置，相关公式如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202308211305909.png" alt="LMH计算"></p><p>其中g是一个学习的函数，bi为偏置项，具体的推导过程如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202308211320739.png" alt="分布计算"></p><h3 id="vqa-bias"><a class="markdownIt-Anchor" href="#vqa-bias"></a> VQA Bias</h3><p>一般指的语言偏置，他会使得模型在回答问题时依赖于问题和答案之间的表面相关性。需要注意的是，这里的偏置区别于归纳偏置，对语言的先验都是存在<strong>坏的语言偏置</strong>和<strong>好的语言上下文</strong>。</p><ul><li>坏的语言偏置：对一个大概率问题不假思索地判断，体现特定的规则。</li><li>好的语言上下文：question的上下文可能存在一些特定规则辅助预测。</li></ul><h3 id="vqa-cp"><a class="markdownIt-Anchor" href="#vqa-cp"></a> VQA CP</h3><p>在文章中提到了VQA-CP的工作提升了模型的鲁棒性，但是在VQA-CP数据集上所做的诸多工作，竟然在一个鲁棒性指标RAD上完全输给了未经过Bias抑制处理的VQA模型。但是从整体上看，抑制偏置的前景是光明的。</p><h3 id="grad-camclass-activation-map"><a class="markdownIt-Anchor" href="#grad-camclass-activation-map"></a> Grad-CAM（Class Activation Map）</h3><p>Gram-CAM发生在卷积的最后一层，绘制热力图，对应给定的类别，了解网络到底关注哪些区域，可视化哪些部分对预测结果的贡献最大。</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202308211528965.png" alt="Grad-CAM生成"></p><p>其计算如下图所示，A代表网络最后一层卷积的输出大小，w代表全联接层的权重大小，c为分类的类别。<img src="https://pic1.zhimg.com/80/v2-4d3b26b1d4717d42a16eb135c8825da4_720w.webp" alt="CAM通用计算公式"></p><h3 id="fvqa"><a class="markdownIt-Anchor" href="#fvqa"></a> FVQA</h3><p>涉及外部知识的VQA任务，利用知识库KB中的某条fact进行计算求解</p><h3 id="the-existing-state-of-the-art-visualexplainable-model-scr"><a class="markdownIt-Anchor" href="#the-existing-state-of-the-art-visualexplainable-model-scr"></a> the existing state-of-the-art visualexplainable model SCR</h3><p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.09998">https://arxiv.org/abs/1905.09998</a></p><p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/jialinwu17/Self_Critical_VQA">https://github.com/jialinwu17/Self_Critical_VQA</a></p><p>还是针对训练数据关注于表面文字的统计规律，因此提出了自我批判的训练目标。这里作者认为模型能够选出更有影响力的图像区域，其取决因素在于人类视觉或文本、QA中的重要词两个因素。</p><h6 id="related-work"><a class="markdownIt-Anchor" href="#related-work"></a> Related work</h6><p>学会了正确的判断方法进行预测时，依旧出现关注某些部分人类标注的特殊区域问题，因此引入自我批评，即出现错误答案惩罚该区域关注度，关键端到端可训练的自我批评方法，实现的方法如下：</p><ul><li>人工标注；</li><li>已有数据集人类文本确定；</li><li>QA对象提取；</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202308220916068.png" alt="整体工作"></p><h3 id="consensus-score"><a class="markdownIt-Anchor" href="#consensus-score"></a> Consensus Score</h3><p>一种聚类的指标，衡量聚类结果的稳定性。</p><h2 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h2><p>视觉问答的发展过度依赖训练集表面的语言相关性，无法推广至具有不同QA分布的测试集，特指Question Only模型，因此从视觉可解释性和问题敏感性两个方面进行训练，给出了CSS训练方案，通过屏蔽图像中的关键对象或问题中的单词，分配不同的基本真值答案，生成大量反事实训练样本，在后续构建的LMH模型中性能显著提高。</p><ul><li>视觉解释：正确的答案+正确的对象识别；</li><li>问题敏感能力：问题内部对象替换后预测答案的变化；</li></ul><h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2><p>纵然vqa有了如VQA v1和VQAv2这类的数据集，但是由于图片标注必然存在误差，因此传统模型更加依赖于表面的语言。并非所有数据集都存在相同分布，新给出的VQA-CP数据集注意到这个问题，能够更全面地分析模型的准确性。总而言之，这些方法要么基于对抗，最小化损失，减少正向偏置，增加反向偏置；要么基于融合，研究如何将两个模型的结果进行合并。</p><p>本文推出了基于对抗的CSS训练方案，分为V-CSS，即对原始图像掩盖，合成反事实图像，构建新的VQ对；Q-CSS，掩盖真实关键词，构建新的VQ对。加入以上两种VQ对，使模型被迫专注于关键的对象和单词。广泛的消融实验证明了模型能力。</p><h2 id="related-work-2"><a class="markdownIt-Anchor" href="#related-work-2"></a> Related Work</h2><ul><li>语言偏差解决办法：平衡数据集或者设计模型减小偏差。</li><li>视觉解释能力：传统的GradCAM虽然能够进行热力图的绘制，但是需要人工标注数据、同时不是端到端的模型（原始的输入，通过模型直接获得结果）。</li><li>问题敏感性：研究的工作较少，相关的研究更加注重更换措辞，并没有关注关键词替换的问题。</li><li>反事实训练样本生成。</li></ul><h2 id="approach"><a class="markdownIt-Anchor" href="#approach"></a> Approach</h2><p>生成特殊的VQ分布，构建自顶向下的模型，合成反事实样本；</p><h3 id="preliminaries"><a class="markdownIt-Anchor" href="#preliminaries"></a> Preliminaries</h3><p>使用问题编码器构建V和Q两个集合，代表不同对象的特征以及不同单词的特征，然后使用fvqa预测答案的分布：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>P</mi><mrow><mi>v</mi><mi>q</mi><mi>a</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">a</mi><mo>∣</mo><mi>I</mi><mo separator="true">,</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>f</mi><mrow><mi>v</mi><mi>q</mi><mi>a</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">V</mi><mo separator="true">,</mo><mi mathvariant="bold-italic">Q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P_{v q a}(\boldsymbol{a} \mid I, Q)=f_{v q a}(\boldsymbol{V}, \boldsymbol{Q})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span><span class="mord mathnormal mtight" style="margin-right:.03588em">q</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol">a</span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:-.10764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span><span class="mord mathnormal mtight" style="margin-right:.03588em">q</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.25555em">V</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">Q</span></span></span><span class="mclose">)</span></span></span></span></span></p><p>这里的fvqa是用了注意力机制以及交叉熵损失，关注于融合模型，放弃结果较差的对抗模型，接下来引入纯问题模型fq，即：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>P</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>f</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P_ {q} (a|Q)= f_ {q} (Q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:-.10764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mclose">)</span></span></span></span></span></p><p>然后将两个结果融合得到分布： $ \widehat {P}_ {vqa} $ (a|I,Q)=M( $ P_ {vqa} $ (a|I,Q), $ P_ {q} $ (a|Q)).</p><h3 id="counterfactual-samples-synthesizing-css"><a class="markdownIt-Anchor" href="#counterfactual-samples-synthesizing-css"></a> Counterfactual Samples Synthesizing (CSS)</h3><p>三个主要步骤，即分别对原始样本、V-CSS以及Q-CSS，其中后两步的实现方法如下图所示</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202308211617604.png" alt="V-CSS和Q-CSS实现伪代码"></p><p>需要注意的是，对应的阈值需要根据不同的模型进行更改，即：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202308211619812.png" alt="四种模型横向纵向对比"></p><h4 id="v-css"><a class="markdownIt-Anchor" href="#v-css"></a> V-CSS</h4><p>初始对象选择：使用SpaCy为question分配磁性标注，提取nouns，计算对象类别和GloVe嵌入结果的余弦相似度，获得最小对象集。</p><p>对象局部贡献计算：改进的Grad-CAM计算，公式如下：</p><p>s(a, $ v_ {i} $ )=S( $ P_ {vqa} $ (a), $ v_ {i} $ ):= $ (V_ {v_ {i}}P_ {vqa}(a))^ {T} $</p><p>关键对象选择：选择前k个对象作为关键对象集，k满足最小数（即softmax计算贡献度结果），需要注意的事本文阈值设置为0.65。</p><p>动态答案分配：生成反例，通过正例带入模型计算结果分布，然后取概率最高的几个作为答案称为集合a+，其他的作为a-，返回a-，这样就获得了反例的a集合。</p><h4 id="q-css"><a class="markdownIt-Anchor" href="#q-css"></a> Q-CSS</h4><p>和Q-CSS相似，单词本地贡献计算、关键单词选择（Q-代表关键词遮盖的句子，Q+代表遮盖其他的句子）和动态答案分配</p><h2 id="experiments"><a class="markdownIt-Anchor" href="#experiments"></a> Experiments</h2><h3 id="hyperparameters-of-v-css-and-q-css"><a class="markdownIt-Anchor" href="#hyperparameters-of-v-css-and-q-css"></a> Hyperparameters of V-CSS and Q-CSS</h3><p>基于LMH模型上的消融实验，结果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202308211734008.png" alt="消融实验结果"></p><p>消融实验的结果：</p><ul><li>随着I 的增大，模型的性能逐渐降低；</li><li>V-CSS关键对象的大小维持在一定的水平，动态k达到了最佳性能。</li><li>Q-CSS关键对象的大小，从结果中可以发现只进行一次替换就能达到最佳性能。</li><li>当sigma为0.5时，准确率最高，效果最好；</li></ul><h3 id="architecture-agnostic"><a class="markdownIt-Anchor" href="#architecture-agnostic"></a> Architecture Agnostic</h3><p>本次实验应用了UpDn、PoE、RUBi、LMH四种模型进行集成，分别计算了不同VQA架构的VQA-CP v2的准确度，均有显著的提升，在基于集成的模型中更为显著</p><p><img src="https://cdn.jsdelivr.net/gh/xhsioi/blog-img@main/202308212057144.png" alt="四种模型横向、纵向比较"></p><h3 id="comparisons-with-state-of-the-arts"><a class="markdownIt-Anchor" href="#comparisons-with-state-of-the-arts"></a> Comparisons with State-of-the-Arts</h3><h4 id="performance-on-vqa-cp-v2-and-vqa-v2"><a class="markdownIt-Anchor" href="#performance-on-vqa-cp-v2-and-vqa-v2"></a> Performance on VQA-CP v2 and VQA v2</h4><p>LMH-CSS，在这两个数据集上分别和最先进的模型比较，即AReg，MuRel、GRL、RUBi等多个模型，进一步降低了语言的偏置作用。</p><h4 id="performance-on-vqa-cp-v1"><a class="markdownIt-Anchor" href="#performance-on-vqa-cp-v1"></a> Performance on VQA-CP v1</h4><p>LMH-CSS和VQA-CP v1最新模型对比，相较于baseline有了一定的提升。</p><h4 id="improving-visual-explainable-ability"><a class="markdownIt-Anchor" href="#improving-visual-explainable-ability"></a> Improving Visual-Explainable Ability</h4><p>研究两个问题，是否能并入集成框架、实现了怎样的提升。</p><p>使用SCR+LMH对比CSS+LMH，可视化可解释的模型不能很容易融入到基于集成的框架中，CSS可以提高一定的性能。</p><p>将计算得到的SIM值作为为标签，得到度量平均值重要性的新指标，即最高前k个对象的平均SIM分数，从而证明视觉解释能力的提升。</p><h3 id="improving-question-sensitive-ability"><a class="markdownIt-Anchor" href="#improving-question-sensitive-ability"></a> Improving Question-Sensitive Ability</h3><p>重点研究CSS对模型鲁棒性和语言敏感性的影响，鲁棒性通过CS（k）等参数确定。语言敏感性部分删除了Q中的部分关键词构建新样本，计算置信度。</p></div><hr><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.88rem}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22ab38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019fe8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fa fa-close"></i></a><h4 class="reward-title">欢迎投喂~</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div></div><script src="/libs/share/js/social-share.min.js"></script><div class="reprint" id="reprint-statement"><p class="reprint-tip"><i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp; <span>转载规则</span></p><div class="center-align"><a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh"><img alt="" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a></div><br><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">《CVPR2020 Counterfactual Samples Synthesizing for Robust VQA Note》 </span>由 <a xmlns:cc="http://creativecommons.org/ns#" href="/2023/08/22/cvpr2020-counterfactual-samples-synthesizing-for-robust-vqa-note/" property="cc:attributionName" rel="cc:attributionURL">xhsioi </a>采用 <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">知识共享署名 4.0 国际许可协议 </a>进行许可。</div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fa fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2023/09/11/mmsegmentation-yu-yi-fen-ge-quan-liu-cheng/"><div class="card-image"><img src="/medias/featureimages/19.jpg" class="responsive-img" alt="MMSegmentation语义分割全流程"> <span class="card-title">MMSegmentation语义分割全流程</span></div></a><div class="card-content article-content"><div class="summary block-with-text">MMSegmentation语义分割全流程 环境安装 在这一部分，我首先安装配置了MMSegmentation，利用colab平台进行搭建，基本的信息如下： 这里使用的GPU为colab给出的基础款，即Tesla T4。 在之后的过程</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2023-09-11 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/Datawhale/" class="post-category" target="_blank">Datawhale</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/" target="_blank"><span class="chip bg-color">语义分割</span> </a><a href="/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/" target="_blank"><span class="chip bg-color">自我提升</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fa fa-chevron-right"></i></div><div class="card"><a href="/2023/05/31/mei-ri-yi-ti-zheng-li-2023-5/"><div class="card-image"><img src="/medias/featureimages/14.jpg" class="responsive-img" alt="每日一题整理——2023-5"> <span class="card-title">每日一题整理——2023-5</span></div></a><div class="card-content article-content"><div class="summary block-with-text">每日一题整理——2023.5 2023.5.1 通知所有员工所需的时间 数据范围： 我的思路; 首先分析需要使用的数据结构，想到了使用树或者并查集作为基本的数据结构。但是后来发现并查集的话计算较为复杂，因此利用线性表构建了简单的树（</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2023-05-31 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/leetcode/" class="post-category" target="_blank">leetcode</a></span></div></div><div class="card-action article-tags"><a href="/tags/c/" target="_blank"><span class="chip bg-color">c++</span> </a><a href="/tags/%E7%AE%97%E6%B3%95/" target="_blank"><span class="chip bg-color">算法</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: cout>>.<<cin<br />作者: xhsioi<br />链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fa fa-list"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><footer class="page-footer bg-color"><div class="container row center-align"><div class="col s12 m8 l8 copy-right">&nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp; <span class="white-color">105.8k</span><br><span id="sitetime"></span><br><span id="busuanzi_container_site_pv" style="display:none"><i class="fa fa-heart-o"></i> 本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span> </span><span id="busuanzi_container_site_uv" style="display:none">人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.</span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fa fa-github"></i> </a><a href="mailto:m18846242315@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa fa-envelope-open"></i> </a><a href="https://zhihu.com/people/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-inverse">知</i> </a><a href="http://wpa.qq.com/msgrd?v=3&uin=2848220300&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2021,10,5,12,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><link rel="stylesheet" href="/css/prism.css"><script src="/js/prism.js" async></script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fa fa-angle-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script type="text/javascript">var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="Σ(っ °Д °;)っ你给我回来李和鑫！",clearTimeout(st)):(document.title="φ(゜▽゜*)♪你回来辣！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"superSample":2,"position":"left","width":150,"height":300,"hOffset":30,"vOffset":-30},"mobile":{"show":true,"scale":0.6},"react":{"opacity":0.7},"name":{"canvas":"live2dcanvas","div":"live2d-widget"},"dev":{"border":false},"dialog":{"enable":true,"hitokoto":true}});</script></body></html>