<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="python数据分析大作业（二）, cout&gt;&gt;.&lt;&lt;cin"><meta name="baidu-site-verification" content="fmlEuI34ir"><meta name="google-site-verification" content="yCy2azpds5XSuGZvis6OuA-XIGF5GuGpYRAaGfD6o48"><meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7"><meta name="description" content="作业二实验报告重要的库import requests
from bs4 import BeautifulSoup
import os
import pandas as pd
import random

from pyecharts imp"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>python数据分析大作业（二） | cout&gt;&gt;.&lt;&lt;cin</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><style type="text/css"></style><script src="/libs/jquery/jquery-2.2.0.min.js"></script><script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ce84511d3df71640a9378a69f6293044";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script>document.write('<script src="https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba" id="sozz"><\/script>')</script><meta name="generator" content="Hexo 5.4.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">cout>>.<<cin</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a><ul class="right"><li class="hide-on-med-and-down"><a href="/" class="waves-effect waves-light"><i class="fa fa-home"></i> <span>首页</span></a></li><li class="hide-on-med-and-down"><a href="/tags" class="waves-effect waves-light"><i class="fa fa-tags"></i> <span>标签</span></a></li><li class="hide-on-med-and-down"><a href="/categories" class="waves-effect waves-light"><i class="fa fa-bookmark"></i> <span>分类</span></a></li><li class="hide-on-med-and-down"><a href="/archives" class="waves-effect waves-light"><i class="fa fa-archive"></i> <span>归档</span></a></li><li class="hide-on-med-and-down"><a href="/about" class="waves-effect waves-light"><i class="fa fa-user-circle-o"></i> <span>关于</span></a></li><li class="hide-on-med-and-down"><a href="/friends" class="waves-effect waves-light"><i class="fa fa-address-book"></i> <span>友情链接</span></a></li><li class="hide-on-med-and-down"><a href="/contact" class="waves-effect waves-light"><i class="fa fa-comments"></i> <span>Contact</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fa fa-search" title="搜索"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">cout>>.<<cin</div><div class="logo-desc">大连理工大学|软件工程|创中</div></div><ul class="menu-list mobile-menu-list"><li><a href="/" class="waves-effect waves-light"><i class="fa fa-fw fa-home"></i> 首页</a></li><li><a href="/tags" class="waves-effect waves-light"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li><a href="/categories" class="waves-effect waves-light"><i class="fa fa-fw fa-bookmark"></i> 分类</a></li><li><a href="/archives" class="waves-effect waves-light"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li><a href="/about" class="waves-effect waves-light"><i class="fa fa-fw fa-user-circle-o"></i> 关于</a></li><li><a href="/friends" class="waves-effect waves-light"><i class="fa fa-fw fa-address-book"></i> 友情链接</a></li><li><a href="/contact" class="waves-effect waves-light"><i class="fa fa-fw fa-comments"></i> Contact</a></li><li><div class="divider"></div></li><li><a href="https://github.com/xhsioi/xhsioi.github.io" class="waves-effect waves-light" target="_blank"><i class="fa fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/xhsioi/xhsioi.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/0.jpg)"><div class="container"><div class="row"><div class="col s12 m12 l12"><div class="brand"><div class="description center-align post-title">python数据分析大作业（二）</div></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px}#toc-content .is-active-link{color:#42b983}#toc-content .is-active-link::before{background-color:#42b983}#floating-toc-btn{position:fixed;right:20px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/python/" target="_blank"><span class="chip bg-color">python</span> </a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BC%8C%E7%88%AC%E8%99%AB/" target="_blank"><span class="chip bg-color">数据分析，爬虫</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" class="post-category" target="_blank">大作业</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-08-30</div><div class="post-author info-break-policy"><i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp; xhsioi</div><div class="info-break-policy"><i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp; 3.2k</div><div class="info-break-policy"><i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp; 13 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="作业二实验报告"><a href="#作业二实验报告" class="headerlink" title="作业二实验报告"></a>作业二实验报告</h1><h2 id="重要的库"><a href="#重要的库" class="headerlink" title="重要的库"></a>重要的库</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
from bs4 import BeautifulSoup
import os
import pandas as pd
import random

from pyecharts import options as opts
from pyecharts.charts import WordCloud, Pie, Bar, Line, Grid
from pyecharts.globals import ThemeType<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据爬取"><a href="#数据爬取" class="headerlink" title="数据爬取"></a>数据爬取</h2><p>根据题干要求，爬取平凡的荣耀中所有演员的词条信息以及对应外链的信息，同时获取浙江卫视、东方卫视的收视率数据。整体的步骤如下：</p><ul><li>获取所有演员相关的html代码；</li><li>依旧遍历每个演员对应的html代码，保存每个演员的姓名以及相关链接；</li><li>根据保存的外链，爬取每个演员对应的基本信息；</li><li>爬取收视率表格；</li><li>将上述数据分别存储为csv文件；</li><li>爬取演员词条中对应演员的照片，存储为jpg文件；</li></ul><h4 id="获取所有演员名单以及相关信息"><a href="#获取所有演员名单以及相关信息" class="headerlink" title="获取所有演员名单以及相关信息"></a>获取所有演员名单以及相关信息</h4><p><strong>相关函数/对象：</strong></p><ul><li><strong>get_data(url)</strong></li><li><strong>process(data)</strong></li></ul><p><img src="https://github.com/xhsioi/blog-img/blob/main/python%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E5%9B%BE%E7%89%87%2010.png?raw=true"></p><p>这一部分使用的仍是BeautifulSoup以及requests中的库函数进行数据爬取。步骤如下：</p><ul><li>爬取标签为dl，属性为{‘class’: ‘info’}的相关html代码；</li><li>查找演员姓名以及对应链接；<ul><li>对于演员姓名，直接选择每组dl中的dt.text；</li><li>对于链接，每个dl标签中只含有一个href属性，因此只需要截取所有dl中的标签为a属性为href的内容即可；</li></ul></li><li>利用得到的外部链接，爬取每个演员的标签为div，属性为{‘class’: ‘basic-info J-basic-info cmn-clearfix’}的html代码；</li><li>同上一题，对内部的dt，dl标签进行遍历，得到每个演员基本信息字典；</li><li>将字典汇总，获得整体数据，等待数据处理。</li></ul><p>代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">def get_data(url):  # 获取对应的演员数据
    #爬取标签为dl，属性为{'class': 'info'}的相关html代码
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) '
                      'Chrome/67.0.3396.99 Safari/537.36 '
    }
    html = requests.get(url, headers=headers)
    html.encoding = "utf-8"
    bs = BeautifulSoup(html.text, "html.parser")
    results = bs.find_all('dl', {'class': 'info'})

    #查找演员姓名以及对应链接
    stars = []
    for res in results:
        star = {}
        star['name'] = res.find('dt').text
        link = res.find('a')
        #对于不存在链接的演员，保存其姓名
        if link is None:
            star['中文名'] = res.find('dt').text
            stars.append(star)
            print("len(stars): {}".format(len(stars)))
            continue
        else:
            #对外链信息进行爬取
            star['link'] = 'https://baike.baidu.com' + link.get('href')
            html_1 = requests.get(star["link"], headers=headers)
            html_1.encoding = "utf-8"
            bs_1 = BeautifulSoup(html_1.text, "html.parser")
            result_1 = bs_1.find('div', {'class': 'basic-info J-basic-info cmn-clearfix'})
            dt = result_1.find_all('dt')
            dd = result_1.find_all('dd')
            item = 0
            for t in dt:
                index = "".join(t.text.split())
                star[index] = dd[item].text.strip()
                item += 1
            stars.append(star)
            print("len(stars): {}".format(len(stars)))
    result_answer = pd.DataFrame(stars)
    return result_answer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="获取演员图片"><a href="#获取演员图片" class="headerlink" title="获取演员图片"></a>获取演员图片</h4><p><strong>相关函数/对象：</strong></p><ul><li><strong>get_pic(url, name, bs)</strong></li><li><strong>pic_check(pics)</strong></li><li><strong>process.get_star_pic(self)</strong></li></ul><p>根据演员的相关链接，爬取img标签属性为{‘alt’: 演员姓名}或者{‘class’: ‘picture’}的src属性，调用pic_check函数进行链接筛选，去除其他非链接的src值，得到图片链接，将图片保存到指定文件夹。代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">def get_pic(url, name, bs):
    pics = bs.find_all('img', {'class': 'picture'})
    urls = pic_check(pics)

    if len(urls) == 0:
        pics = bs.find_all('img', {'alt': name})
        urls = pic_check(pics)

    for i, url in enumerate(urls):
        path = 'data/' + 'pics/' + name + '/'
        if not os.path.exists(path):
            os.makedirs(path)
        picture = requests.get(url, timeout=15)
        pic_path = str(i + 1) + '.jpg'
        with open(path + pic_path, 'wb') as f:
            f.write(picture.content)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="获取收视率等信息"><a href="#获取收视率等信息" class="headerlink" title="获取收视率等信息"></a>获取收视率等信息</h4><p><strong>相关函数/对象：</strong></p><p><strong>get_table(url)</strong></p><p><img src="https://github.com/xhsioi/blog-img/blob/main/python%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E5%9B%BE%E7%89%87%2011.png?raw=true"></p><p>根据百度百科的显示，收视率数据主要是来自于浙江卫视和东方卫视，因此只需要爬取收视情况即可。爬取的过程如下：</p><ul><li>通过观察前端代码可知，爬取标签为table，属性为{‘log-set-param’:’table_view’,’data-sort’:’sortDisabled’}的数据即可；</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) '
                  'Chrome/67.0.3396.99 Safari/537.36 '
}
html = requests.get(url, headers=headers)
html.encoding = "utf-8"
bs = BeautifulSoup(html.text, "html.parser")
results = bs.find_all('table',{'log-set-param':'table_view','data-sort':'sortDisabled'})<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>观察爬取的tables，选取最后一个表格作为最终分析对象，遍历内部的tr,td标签，找到每一个div标签对应的text；</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">#长度为4，取最后一个表格为爬取对象
show_list = []
trs = results[3].find_all('tr')
for tr in trs:
    tds = tr.find_all('td')
    temp_list = []
    for td in tds:
        temp_list.append(td.find('div').text)
    show_list.append(temp_list)
fin_table = pd.DataFrame(show_list)
fin_table.drop(fin_table.index[0])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>处理数据，重置index和columns；</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">#处理数据
df = fin_table[1:]
arr = df.values
df = pd.DataFrame(arr[1:, 1:], index=arr[1:, 0], columns=arr[0, 1:])
df.index.name = arr[0, 0]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>将数据分别存储，获得‘东方卫视CSM59城收视.csv’和‘浙江卫视CSM59城收视.csv’；</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">#存储
df_1.to_csv('data\\result\\{}.csv'.format(fin_table.iloc[0,1]))
df_2.to_csv('data\\result\\{}.csv'.format(fin_table.iloc[0,2]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p><strong>相关函数/对象：</strong></p><p><strong>process(data)</strong></p><p>这一部分对数据进行的处理：</p><ul><li>去除数据中含有的多余字符；</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">df = df.replace('\n', ' ', regex=True)
df = df.replace(u"\\[.*?]", "", regex=True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>删去columns中含有的特殊符号；</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">df = df.replace(u"\xa0", "", regex=True)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>对中文名属性进行分列处理，得到中文名和角色名两个属性；</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">df['中文名'] = df['name'].map(lambda x: x.split('饰')[0])
df['角色名'] = df['name'].map(lambda x: x.split('饰')[1])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>最后将结果存储为’data/result/result_2.csv’。</p><h2 id="数据可视化分析"><a href="#数据可视化分析" class="headerlink" title="数据可视化分析"></a>数据可视化分析</h2><p>这一部分使用的仍是pyecharts。</p><h4 id="参演人员统计"><a href="#参演人员统计" class="headerlink" title="参演人员统计"></a>参演人员统计</h4><p><strong>相关函数/对象：</strong></p><p><strong>process.process_list(self)</strong></p><p>首先提取data中的中文名属性，考虑到词云统计更加适应演员名单的显示，因此这里仍使用词云进行表示统计结果。对于权重的确认，我们根据爬取的顺序，即百度百科显示的顺序进行赋权，通过不断缩小随机数的范围使得更为重要的演员突出。代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">for name in df:
    # 根据爬取顺序确定权重
    result[name] = str(random.randint(100, temp))
    temp = temp - 10
result = [(a, b) for a, b in result.items()]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后绘制词云图，存储为”data/htmls/平凡的荣耀参演人员统计.html”</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 绘制词云图
word_cloud = (
    WordCloud()
        .add("平凡的荣耀", result, word_size_range=[20, 60],
             textstyle_opts=opts.TextStyleOpts(font_family="Fantasy"))
        .set_global_opts(title_opts=opts.TitleOpts(title="平凡的荣耀参演人员",
                                                   title_link="https://baike.baidu.com/item/%E5%B9%B3%E5%87%A1%E7%9A%84%E8%8D%A3%E8%80%80",
                                                   subtitle="xhsioi",
                                                   subtitle_link="https://xhsioi.github.io/"))
)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可视化结果如下：</p><p><img src="https://github.com/xhsioi/blog-img/blob/main/python%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E5%9B%BE%E7%89%87%2012.png?raw=true"></p><p>可以看到，主演赵又廷、庞瀚辰等人在图表中更为突出，其他配角位于边缘，简洁明了地体现出了演员在剧中角色的分量。</p><h4 id="毕业院校统计"><a href="#毕业院校统计" class="headerlink" title="毕业院校统计"></a>毕业院校统计</h4><p><strong>相关函数/对象：</strong></p><p><strong>process.process_school(self)</strong></p><p>首先提取data中的毕业院校属性，对该属性进行筛选，截取其中包含’大学’, ‘学院’, ‘话剧团’, ‘话剧院’的有效前缀字符串，得到数据后对毕业院校进行计数，汇总得出对应的毕业院校字典。筛选过程如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">temp = df['毕业院校'].values.tolist()
check = ['大学', '学院', '话剧团', '话剧院']
school_result = []
for ch in check:
    school_result = school_result + [str(x).partition(ch)[0] + ch for x in temp if
                                     len(str(x).partition(ch)[0]) != len(str(x))]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将字典转化成list，进行饼状图可视化分析，存储为”data/htmls/毕业院校统计.html”，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 可视化分析
pie = (
    Pie().add(
        series_name="毕业学校统计",
        data_pair=[list(z) for z in temp],
        radius=["40%", "80%"]
    )
        .set_global_opts(
        title_opts=opts.TitleOpts(title="演员毕业学校统计",
                                  title_link="https://space.bilibili.com/2018113152/",
                                  subtitle="xhsioi",
                                  subtitle_link="https://xhsioi.github.io/"),
        legend_opts=opts.LegendOpts(orient="vertical", pos_top="10%", pos_left="2%")
    )
        .set_series_opts(
        label_opts=opts.LabelOpts(formatter="{b}")
    )
)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可视化结果如下图所示，鼠标悬停特定区域可以获取对应毕业院校毕业人数：</p><p><img src="https://github.com/xhsioi/blog-img/blob/main/python%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E5%9B%BE%E7%89%87%2013.png?raw=true"></p><p>从演员毕业学校可视化结果可以看出，平凡的荣耀中中央戏剧学院、北京电影学院、上海戏剧学院的人数最多，分别为14，9，4。不仅有国内的大学表演系毕业生，还有一位来自维多利亚的毕业生参与了电视剧的制作。同时，我们看到话剧团或话剧院的毕业生也参与了电视剧的制作，话剧演员的加入让电视剧具有了一丝话剧的趣味。</p><h4 id="收视率、收视份额可视化分析"><a href="#收视率、收视份额可视化分析" class="headerlink" title="收视率、收视份额可视化分析"></a>收视率、收视份额可视化分析</h4><p><strong>相关函数/对象：</strong></p><p><strong>process.process_school(self)</strong></p><p>首先分别获取两个卫视的播出日期、收视率、收视份额三项数据，同时完成数据类型转换：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">df_1 = pd.read_csv('data/result/东方卫视CSM59城收视.csv')
df_2 = pd.read_csv('data/result/浙江卫视CSM59城收视.csv')
show_time = df_1['播出日期'].astype(str).values.tolist()
watch_rate_1 = df_1['收视率%'].astype(float).values.tolist()
watch_rate_2 = df_2['收视率%'].astype(float).values.tolist()
watch_per_1 = df_1['收视份额%'].astype(float).values.tolist()
watch_per_2 = df_2['收视份额%'].astype(float).values.tolist()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>绘制综合收视率、收视份额的组合图，这里使用grid将折线图和柱状图进行整合，将结果存储为”data/htmls/收视数据统计.html”，相关代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 收视率
bar_1 = (
    Bar()
        .add_xaxis(show_time)
        .add_yaxis(
        "东方卫视收视率",
        [round(x, 1) for x in watch_rate_1],
        yaxis_index=0,
        color="#d14a61"
    )
        .add_yaxis(
        "浙江卫视收视率",
        [round(x, 1) for x in watch_rate_2],
        yaxis_index=0,
        color="#5793f3"
    )
        .extend_axis(
        yaxis=opts.AxisOpts(
            name="收视份额",
            type_="value",
            min_=0.0,
            max_=12.0,
            position="left",
            axisline_opts=opts.AxisLineOpts(
                linestyle_opts=opts.LineStyleOpts(color="#675bba")
            ),
            axislabel_opts=opts.LabelOpts(formatter="{value} %")
        )
    )
        .set_global_opts(
        title_opts=opts.TitleOpts(title="收视率可视化分析", subtitle="xhsioi"),
        legend_opts=opts.LegendOpts(pos_left="50%"),
        tooltip_opts=opts.TooltipOpts(trigger="axis", axis_pointer_type="cross"),
        yaxis_opts=opts.AxisOpts(
            name="收视率",
            min_=0.0,
            max_=4.0,
            position="right",
            offset=80,
            axisline_opts=opts.AxisLineOpts(
                linestyle_opts=opts.LineStyleOpts(color="#5793f3")
            ),
            axislabel_opts=opts.LabelOpts(formatter="{value} %"),
        )
    )
)
#收视份额
line_1 = (
    Line()
        .add_xaxis(show_time)
        .add_yaxis(
        "东方卫视收视份额",
        [round(x, 1) for x in watch_per_1],
        yaxis_index=1,
        color="#2F4DC9",
    )
        .add_yaxis(
        "浙江卫视收视份额",
        [round(x, 1) for x in watch_per_2],
        yaxis_index=1,
        color="#A6CE1B",
    )
        .set_series_opts(label_opts=opts.LabelOpts(is_show=False))
)
#柱状图覆盖
bar_1.overlap(line_1)
grid = Grid(init_opts=opts.InitOpts(width="1600px"))
grid.add(bar_1, opts.GridOpts(pos_left="15%", pos_right="15%"), is_control_axis_index=True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可视化结果如下图所示，将鼠标悬停在某一点，显示当前点的坐标以及各个卫视的收视率和收视份额。</p><p><img src="https://github.com/xhsioi/blog-img/blob/main/python%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E5%9B%BE%E7%89%87%2014.png?raw=true"></p><p>通过收视率、收视份额可视化结果可知，各个卫视的收视率、收视份额整体的变化趋势是相近的，两个卫视的收视数据都在9.12和9.27达到了峰值。对于东方卫视，9.12收视率为2.7%、收视份额为9.7%；9.27收视率为3%，收视份额10.7%。对于浙江卫视，9.12收视率为2.1%、收视份额为7.5%；9.27收视率为2.4%，收视份额为8.4%。</p><p>对于不同卫视的收视份额以及收视率，从峰值数据来看，东方卫视份额要高于浙江卫视，从整体来看，东方卫视和浙江卫视的数据大致相同。因此我们可以看出每天通过两个卫视观看该电视剧的观众比例大致相同，但从实际的收视份额来看，在剧情迎来转折或者结局时，更多的观众愿意通过东方卫视进行观看。</p><p>最后，可以看出收视率变化相较于收视份额变化较为平缓，体现出电视剧前期收视数据逐步升高，中期收视数据较为平稳，后期收视数据突然提高的特点。</p><h4 id="收视排名分析"><a href="#收视排名分析" class="headerlink" title="收视排名分析"></a>收视排名分析</h4><p><strong>相关函数/对象：</strong></p><p><strong>process.process_rank(self)</strong></p><p>首先分别获取两个卫视的电视剧收视排行信息，同时完成数据类型转换：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">df_1 = pd.read_csv('data/result/浙江卫视CSM59城收视.csv')
df_2 = pd.read_csv('data/result/东方卫视CSM59城收视.csv')
rank_1 = df_1['排名'].astype(str).values.tolist()
rank_2 = df_2['排名'].astype(str).values.tolist()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>对排名的数据进行计数，得到排名字典，将字典转为list之后进行排序，东方卫视的排名数据整理代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">results_1 = {}
for rs in rank_1:
    results_1[rs] = results_1.get(rs, 0) + 1
temp_1 = [(a, b) for a, b in results_1.items()]
temp_1 = sorted(temp_1, key=(lambda x: x[0]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>绘制两个电视台的平凡的荣耀收视排名饼状图，将文件存储为”data/htmls/收视排名分析.html”：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">pie = (
    Pie(init_opts=opts.InitOpts(theme=ThemeType.MACARONS))
        .add(
        "浙江卫视收视排名",
        [list(z) for z in temp_1],
        center=["20%", "30%"],
        radius=[40, 80],
        label_opts=opts.LabelOpts(formatter="浙江", position="center")
    )
        .add(
        "东方卫视收视排名",
        [list(z) for z in temp_2],
        center=["55%", "30%"],
        radius=[40, 80],
    )
        .set_global_opts(
        title_opts=opts.TitleOpts(title="收视排名分析", subtitle="xhsioi"),
        legend_opts=opts.LegendOpts(
            type_="scroll",
            pos_top="20%",
            pos_left="80%",
            orient="vertical"
        )
    )
        .set_series_opts(
        label_opts=opts.LabelOpts(formatter="第{b}名:{d}%")
    )
)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可视化结果如下，鼠标悬停于制定区域可以获得对应电视台信息以及当前排名对应的天数：</p><p><img src="https://github.com/xhsioi/blog-img/blob/main/python%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/%E5%9B%BE%E7%89%87%2015.png?raw=true"></p><p>从上图可以看出，该电视剧在浙江卫视41.67%的播出时间内收视第二名；在东方卫视41.67%的播出时间内收视第四名。此外，浙江卫视在接近75%的播出时间内斗占据着浙江卫视的收视前三名，与之形成对比的东方卫视只有接近一半的播出时间平凡的荣耀占据收视前三名。</p><p>可视化的所有结果汇总于”合并.html”。</p></div><hr><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.88rem}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22ab38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019fe8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fa fa-close"></i></a><h4 class="reward-title">欢迎投喂~</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div></div><script src="/libs/share/js/social-share.min.js"></script><div class="reprint" id="reprint-statement"><p class="reprint-tip"><i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp; <span>转载规则</span></p><div class="center-align"><a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh"><img alt="" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a></div><br><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">《python数据分析大作业（二）》 </span>由 <a xmlns:cc="http://creativecommons.org/ns#" href="/2022/08/30/python-shu-ju-fen-xi-da-zuo-ye-er/" property="cc:attributionName" rel="cc:attributionURL">xhsioi </a>采用 <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">知识共享署名 4.0 国际许可协议 </a>进行许可。</div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fa fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2022/08/30/python-shu-ju-fen-xi-da-zuo-ye-san-ji-qi-xue-xi-de-wei-xing-waf/"><div class="card-image"><img src="/medias/featureimages/27.jpg" class="responsive-img" alt="python数据分析大作业（三）——机器学习的微型WAF"> <span class="card-title">python数据分析大作业（三）——机器学习的微型WAF</span></div></a><div class="card-content article-content"><div class="summary block-with-text">恶意URL检测：基于TF-IDF特征向量进行机器学习的微型WAF数据源： Github开源数据集https://github.com/faizann24/Using-machine-learning-to-detect-malicious-</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2022-08-30 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" class="post-category" target="_blank">大作业</a></span></div></div><div class="card-action article-tags"><a href="/tags/python/" target="_blank"><span class="chip bg-color">python</span> </a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BC%8C%E7%88%AC%E8%99%AB/" target="_blank"><span class="chip bg-color">数据分析，爬虫</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fa fa-chevron-right"></i></div><div class="card"><a href="/2022/08/30/python-shu-ju-fen-xi-da-zuo-ye-yi/"><div class="card-image"><img src="/medias/featureimages/10.jpg" class="responsive-img" alt="python数据分析大作业（一）"> <span class="card-title">python数据分析大作业（一）</span></div></a><div class="card-content article-content"><div class="summary block-with-text">作业一实验报告重要的库from random import random import pandas as pd import numpy as np import get_data as crawlers from itertools</div><div class="publish-info"><span class="publish-date"><i class="fa fa-clock-o fa-fw icon-date"></i>2022-08-30 </span><span class="publish-author"><i class="fa fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" class="post-category" target="_blank">大作业</a></span></div></div><div class="card-action article-tags"><a href="/tags/python/" target="_blank"><span class="chip bg-color">python</span> </a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BC%8C%E7%88%AC%E8%99%AB/" target="_blank"><span class="chip bg-color">数据分析，爬虫</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: cout>>.<<cin<br />作者: xhsioi<br />链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fa fa-list"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><footer class="page-footer bg-color"><div class="container row center-align"><div class="col s12 m8 l8 copy-right">&nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp; <span class="white-color">89.4k</span><br><span id="sitetime"></span><br><span id="busuanzi_container_site_pv" style="display:none"><i class="fa fa-heart-o"></i> 本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span> </span><span id="busuanzi_container_site_uv" style="display:none">人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.</span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fa fa-github"></i> </a><a href="mailto:m18846242315@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa fa-envelope-open"></i> </a><a href="https://zhihu.com/people/xhsioi" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-inverse">知</i> </a><a href="http://wpa.qq.com/msgrd?v=3&uin=2848220300&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50"><i class="fa fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2021,10,5,12,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><link rel="stylesheet" href="/css/prism.css"><script src="/js/prism.js" async></script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fa fa-angle-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script type="text/javascript">var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="Σ(っ °Д °;)っ你给我回来李和鑫！",clearTimeout(st)):(document.title="φ(゜▽゜*)♪你回来辣！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/miku.model.json"},display:{superSample:2,position:"left",width:150,height:300,hOffset:30,vOffset:-30},mobile:{show:!0,scale:.6},react:{opacity:.7},name:{canvas:"live2dcanvas",div:"live2d-widget"},dev:{border:!1},dialog:{enable:!0,hitokoto:!0}})</script></body></html>